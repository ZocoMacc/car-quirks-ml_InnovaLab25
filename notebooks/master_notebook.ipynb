{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Imports & Settings\n",
        "- Descargar e importar dependencias"
      ],
      "metadata": {
        "id": "ryKe98J-Bu0M"
      },
      "id": "ryKe98J-Bu0M"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Dummy baseline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, r2_score, mean_squared_error\n",
        "\n",
        "# Preprocessing (Pipelines)\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# Modeling: Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Modeling: Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Modeling: LightGBM\n",
        "# Suprimir warnings (LGBM suele ser sucio con las warnings)\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", message=\".*Unknown parameter.*\")\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Modeling: XGBoost\n",
        "!pip install xgboost\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Deployment\n",
        "import joblib"
      ],
      "metadata": {
        "id": "eE1_V_wWBq4H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d891bb03-9e32-4038-a6b7-be78dbf714ee"
      },
      "id": "eE1_V_wWBq4H",
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.15.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Data\n",
        "- Cargar el data set\n",
        "- Primer vistazo a la distribucion"
      ],
      "metadata": {
        "id": "QctRhgn6B40Z"
      },
      "id": "QctRhgn6B40Z"
    },
    {
      "cell_type": "code",
      "source": [
        "# Get url from file hosted on GitHub\n",
        "url = \"https://raw.githubusercontent.com/ZocoMacc/car-quirks-ml_InnovaLab25/refs/heads/main/data/cars_data.csv\"\n",
        "\n",
        "# Cargar csv en un DataFrame\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Explorar la estructura del DataFrame (Sanity Check)\n",
        "df.info()\n",
        "df.shape\n",
        "# df.isna().sum().sort_values(ascending=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzqNHCXUCZTN",
        "outputId": "1797e019-1fcd-4b2e-b34e-3578d908f4ab"
      },
      "id": "EzqNHCXUCZTN",
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 15 columns):\n",
            " #   Column                  Non-Null Count  Dtype  \n",
            "---  ------                  --------------  -----  \n",
            " 0   name                    10000 non-null  object \n",
            " 1   year                    10000 non-null  int64  \n",
            " 2   selling_price           10000 non-null  int64  \n",
            " 3   km_driven               10000 non-null  int64  \n",
            " 4   fuel                    10000 non-null  int64  \n",
            " 5   combustible_estimado_l  10000 non-null  float64\n",
            " 6   seller_type             10000 non-null  int64  \n",
            " 7   transmission            10000 non-null  int64  \n",
            " 8   owner                   10000 non-null  int64  \n",
            " 9   tipo_carroceria         10000 non-null  int64  \n",
            " 10  potencia_motor_hp       10000 non-null  int64  \n",
            " 11  nivel_seguridad         10000 non-null  float64\n",
            " 12  calidad_auto            10000 non-null  object \n",
            " 13  score_calidad           10000 non-null  float64\n",
            " 14  eficiencia_km_l         10000 non-null  float64\n",
            "dtypes: float64(4), int64(9), object(2)\n",
            "memory usage: 1.1+ MB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 15)"
            ]
          },
          "metadata": {},
          "execution_count": 243
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ver el balance de las clases (84% Media, 10.5% Alta, 5.5% Baja)\n",
        "df[\"calidad_auto\"].value_counts(normalize=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "tfZjya5Ya2MI",
        "outputId": "c7a12075-c619-4549-b92c-39a7a494e56d"
      },
      "id": "tfZjya5Ya2MI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "calidad_auto\n",
              "Media    0.8399\n",
              "Alta     0.1052\n",
              "Baja     0.0549\n",
              "Name: proportion, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>proportion</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>calidad_auto</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Media</th>\n",
              "      <td>0.8399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Alta</th>\n",
              "      <td>0.1052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Baja</th>\n",
              "      <td>0.0549</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Lo que esto nos dice\n",
        "- Un fuerte desbalanceo de clases\n",
        "  - \"Media\" es la mayoria con un 84%\n",
        "  - \"Alta\" solo cubre el 10%, y \"Baja\" solo un 5.5%\n",
        "- El accuracy de referencia (baseline) es enga√±osamente alto\n",
        "  - Un DummyClassifier que siempre predice \"Media\" deberia de poder predecir 83.99%.\n",
        "  - Superar este baseline no garantiza que el modelo sea mas precizo detectando \"Alta\" o \"Baja\".\n",
        "- Riesgo de abandono de las clases minoritarias\n",
        "  - El modelo tiene el riesgo de predecir \"Media\" la mayoria del tiempo debido al desbalanceo de las clases, lo que podria ignorar \"Alta\" o \"Baja\" como opciones."
      ],
      "metadata": {
        "id": "4s-HoOX8IJAh"
      },
      "id": "4s-HoOX8IJAh"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cleaning & Dropping\n",
        "- Decidir las variables que seran ignoradas por el modelo.\n",
        "- Si es necesarion, transformar valores en interpretaciones legibles por el modelo o marcarlas con una categoria."
      ],
      "metadata": {
        "id": "EujHrAybfup-"
      },
      "id": "EujHrAybfup-"
    },
    {
      "cell_type": "code",
      "source": [
        "# Duda sobre la variable \"score_calidad\": Que tanto se correlaciona con \"calidad_auto\"\n",
        "# Mapear las categorias con numeros para calcular la correlacion\n",
        "mapping = {\"Baja\": 0, \"Media\": 1, \"Alta\": 2}\n",
        "df[\"calidad_code\"] = df[\"calidad_auto\"].map(mapping)\n",
        "\n",
        "# Calcular la correlacion\n",
        "corr = df[[\"score_calidad\", \"calidad_code\"]].corr().iloc[0, 1]\n",
        "\n",
        "# Imprimir los resultados\n",
        "print(f\"Correlacion entre score_calidad y calidad_auto: {corr:.3f}\")\n",
        "\n",
        "# Ver correlaciones para identificar leaks\n",
        "corr_X = df.drop(columns=[\"name\"])\n",
        "correlations = corr_X.drop(columns=[\"calidad_auto\"]).corrwith(corr_X[\"calidad_code\"])\n",
        "print(\"Correlaciones\")\n",
        "print(correlations.sort_values(ascending=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kA-E2kkjgLhv",
        "outputId": "3e2d4521-7c48-48d2-a582-00011a197676"
      },
      "id": "kA-E2kkjgLhv",
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlacion entre score_calidad y calidad_auto: 0.740\n",
            "Correlaciones\n",
            "calidad_code              1.000000\n",
            "score_calidad             0.740022\n",
            "eficiencia_km_l           0.526133\n",
            "nivel_seguridad           0.497154\n",
            "year                      0.495617\n",
            "potencia_motor_hp         0.294303\n",
            "transmission              0.197374\n",
            "selling_price             0.103824\n",
            "fuel                      0.031103\n",
            "seller_type               0.028950\n",
            "km_driven                -0.024826\n",
            "tipo_carroceria          -0.033271\n",
            "owner                    -0.045147\n",
            "combustible_estimado_l   -0.107143\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Lo que esto nos dice\n",
        "- La correlacion entre \"score_calidad\" y \"calidad_auto\" no es 1.0, lo que quiere decir que \"calidad_auto\" no depende al 100% de la variable \"score_calidad\".\n",
        "- La variable \"score_calidad\" va a ser considerada."
      ],
      "metadata": {
        "id": "ZTNtSbS-hsXo"
      },
      "id": "ZTNtSbS-hsXo"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Extraer marca del nombre\n",
        "- Usar el nombre y cortarlo de una manera en la que podamos extrar la marca del auto para poder usarlo como variable y ser considerada."
      ],
      "metadata": {
        "id": "W7UU6SNHlHoE"
      },
      "id": "W7UU6SNHlHoE"
    },
    {
      "cell_type": "code",
      "source": [
        "# Funci√≥n para extraer la marcaa\n",
        "def extract_brand(df, carname_col='name'):\n",
        "    \"\"\"\n",
        "    Extrae la marca ('brand') desde la columna carname_col en el DataFrame df.\n",
        "    La marca es la primera palabra del nombre del auto, en min√∫sculas.\n",
        "\n",
        "    Devuelve el mismo DataFrame con una columna nueva: 'brand'.\n",
        "    \"\"\"\n",
        "    df['brand'] = df[carname_col].str.split(' ').str[0].str.lower()\n",
        "    return df\n",
        "\n",
        "# Aplicar la funci√≥n\n",
        "df = extract_brand(df)\n",
        "\n",
        "# Mostrar las primeras filas con la nueva columna\n",
        "print(df[['name', 'brand']].head())\n",
        "\n",
        "# Ver las marcas √∫nicas y su conteo\n",
        "print(\"\\nCantidad de marcas √∫nicas:\", df['brand'].nunique())\n",
        "print(df['brand'].value_counts().head(29))"
      ],
      "metadata": {
        "id": "-0SgRIRHmF5z",
        "outputId": "0f6a9ade-5937-4048-8293-8d5ea4822c34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "-0SgRIRHmF5z",
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                       name    brand\n",
            "0             Maruti 800 AC   maruti\n",
            "1  Maruti Wagon R LXI Minor   maruti\n",
            "2      Hyundai Verna 1.6 SX  hyundai\n",
            "3    Datsun RediGO T Option   datsun\n",
            "4     Honda Amaze VX i-DTEC    honda\n",
            "\n",
            "Cantidad de marcas √∫nicas: 29\n",
            "brand\n",
            "maruti           2413\n",
            "hyundai          1724\n",
            "mahindra          907\n",
            "tata              897\n",
            "honda             675\n",
            "ford              669\n",
            "toyota            546\n",
            "chevrolet         422\n",
            "volkswagen        326\n",
            "renault           300\n",
            "skoda             201\n",
            "audi              164\n",
            "nissan            164\n",
            "fiat              140\n",
            "mercedes-benz     109\n",
            "bmw                93\n",
            "datsun             93\n",
            "land               25\n",
            "jaguar             22\n",
            "mitsubishi         20\n",
            "volvo              18\n",
            "ambassador         14\n",
            "jeep               13\n",
            "opelcorsa          10\n",
            "kia                 9\n",
            "mg                  8\n",
            "daewoo              6\n",
            "force               6\n",
            "isuzu               6\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Convertir columnas de enteros en categorias\n",
        "- Columnas como \"fuel\", \"seller_type\", \"transmission\", \"owner\", \"tipo_carroceria\" tienen asignado un valor entero pero en realidad representan categorias sin orden.\n",
        "- Convertir estas variables a Pandas' category dtype para mas claridad y eficiencia en la manipulacion de estas variables, tambien es mas seguro hacerlo de esta forma, asi evitamos que estas columnas se interpreten como numeric imputers o scalers."
      ],
      "metadata": {
        "id": "43A-JGJKnxf2"
      },
      "id": "43A-JGJKnxf2"
    },
    {
      "cell_type": "code",
      "source": [
        "cat_int_cols = [\n",
        "    \"fuel\",\n",
        "    \"seller_type\",\n",
        "    \"transmission\",\n",
        "    \"owner\",\n",
        "    \"tipo_carroceria\",\n",
        "    \"brand\"             # categoria extraida del nombre\n",
        "]\n",
        "\n",
        "for col in cat_int_cols:\n",
        "    df[col] = df[col].astype(\"category\")"
      ],
      "metadata": {
        "id": "CZlrE_CHn9ZP"
      },
      "id": "CZlrE_CHn9ZP",
      "execution_count": 246,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Droppear columnas innecesarias\n",
        "- Calcular correlaciones entre las columnas para identificar cual tiene un gran efecto en \"calidad_auto\"\n",
        "- Definir X, y para entrenamiento"
      ],
      "metadata": {
        "id": "xJL2hxc2NKNk"
      },
      "id": "xJL2hxc2NKNk"
    },
    {
      "cell_type": "code",
      "source": [
        "# Al final se droppea el nombre (ya habiendo extraido la brand)\n",
        "df = df.drop(columns=[\"name\"])\n",
        "\n",
        "# Tirar la columna helper que definimos previemente\n",
        "df = df.drop(columns=[\"calidad_code\"])\n",
        "\n",
        "print(\"\\nColumnas que permanecen en el DataFrame:\")\n",
        "print(df.dtypes)  # Checar las columnas que permanecen\n",
        "\n",
        "# Definir X & y para el training\n",
        "features_to_drop = [\"calidad_auto\", \"score_calidad\", \"combustible_estimado_l\", \"km_driven\", \"owner\", \"seller_type\", \"fuel\" ]\n",
        "# features_to_drop = [\"calidad_auto\", \"score_calidad\", \"combustible_estimado_l\", \"km_driven\", \"owner\", \"seller_type\", \"fuel\", \"selling_price\", \"transmission\"]\n",
        "X = df.drop(columns=features_to_drop)\n",
        "y = df[\"calidad_auto\"]    # Estableciendo el target\n",
        "\n",
        "# Inspeccionar las variables que permanecen\n",
        "# print(\"Columnas a considerar:\\n\", X.columns.tolist())\n",
        "print(\"\\nFeature dtypes (para X):\")\n",
        "print(X.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "te-8G4rdNOT0",
        "outputId": "4691d921-87c0-468f-8330-1d47b42c8030"
      },
      "id": "te-8G4rdNOT0",
      "execution_count": 247,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Columnas que permanecen en el DataFrame:\n",
            "year                         int64\n",
            "selling_price                int64\n",
            "km_driven                    int64\n",
            "fuel                      category\n",
            "combustible_estimado_l     float64\n",
            "seller_type               category\n",
            "transmission              category\n",
            "owner                     category\n",
            "tipo_carroceria           category\n",
            "potencia_motor_hp            int64\n",
            "nivel_seguridad            float64\n",
            "calidad_auto                object\n",
            "score_calidad              float64\n",
            "eficiencia_km_l            float64\n",
            "brand                     category\n",
            "dtype: object\n",
            "\n",
            "Feature dtypes (para X):\n",
            "year                    int64\n",
            "selling_price           int64\n",
            "transmission         category\n",
            "tipo_carroceria      category\n",
            "potencia_motor_hp       int64\n",
            "nivel_seguridad       float64\n",
            "eficiencia_km_l       float64\n",
            "brand                category\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DummyClassifier & Baseline\n",
        "- El primer paso es establecer una baseline y asegurarse de que la informacion esta limpia\n",
        "- El objetivo es confirmar ques este DummyClassifier de como resultado una precision de 83.99%\n",
        "- Se usara la estrategia de \"most_frequent\", simplemente el valor que mas se repite sera elegido para la prediccion.\n",
        "- Este modelo representa el piso (baseline) de qualquier modelo futuro.\n",
        "- El split para entrenamiento es un 80/20 asegurandose de que cada clase aparece con las misma proporciones.\n",
        "\n"
      ],
      "metadata": {
        "id": "Ng1LdD5yB6_t"
      },
      "id": "Ng1LdD5yB6_t"
    },
    {
      "cell_type": "code",
      "source": [
        "# Establecer split (Train/Test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.2,    # 80/20 split\n",
        "    stratify=y,       # preserva los ratios 84/10.5/5.5 para train y test\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Test\n",
        "# print(\"Train class proportions:\\n\", y_train.value_counts(normalize=True))\n",
        "# print(\"\\nTest class proportions:\\n\", y_test.value_counts(normalize=True))\n",
        "\n",
        "# Iniciar DummyClassifier\n",
        "dummy = DummyClassifier(\n",
        "    strategy=\"most_frequent\", # Siempre predice la clase mas frecuente (\"Media\")\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "dummy.fit(X_train, y_train)     # \"Entrena\" basado en la clase mas frecuente\n",
        "\n",
        "# Obtener predicciones\n",
        "y_pred = dummy.predict(X_test)  # Aplica la regla a cada fila de X_test\n",
        "\n",
        "# Evaluar accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)   # Fraccion de predicciones correctas\n",
        "print(f\"DummyClassifier Accuracy: {accuracy}\")\n",
        "\n",
        "# Visualizar resulatdos de predicciones\n",
        "print(\"Classification report:\\n\")\n",
        "print(classification_report(\n",
        "    y_test,\n",
        "    y_pred,\n",
        "    digits=4,         # Numero de decimales\n",
        "    zero_division=0   # Ignorar zero-division errors (debido a strings)\n",
        "))\n",
        "\n",
        "# Generar confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred, labels=[\"Media\",\"Alta\",\"Baja\"])\n",
        "print(\"Confusion Matrix:\\n\", cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WC8kJNPZM2Xt",
        "outputId": "500aee12-ec01-40c3-d2a3-19f3650fc4c2"
      },
      "id": "WC8kJNPZM2Xt",
      "execution_count": 248,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DummyClassifier Accuracy: 0.84\n",
            "Classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Alta     0.0000    0.0000    0.0000       210\n",
            "        Baja     0.0000    0.0000    0.0000       110\n",
            "       Media     0.8400    1.0000    0.9130      1680\n",
            "\n",
            "    accuracy                         0.8400      2000\n",
            "   macro avg     0.2800    0.3333    0.3043      2000\n",
            "weighted avg     0.7056    0.8400    0.7670      2000\n",
            "\n",
            "Confusion Matrix:\n",
            " [[1680    0    0]\n",
            " [ 210    0    0]\n",
            " [ 110    0    0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Lo que esto nos dice\n",
        "- Tenemos un baseline de ~84% accuracy, este es el objetivo a vencer en los proximos modelos."
      ],
      "metadata": {
        "id": "wgRyZpmLYjPP"
      },
      "id": "wgRyZpmLYjPP"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data preprocessing\n",
        "- Preparar el data set para ser procesado\n",
        "- Dividir entre variables numericas y categoricas\n",
        "- Implementar un pipeline para cada tipo de variable\n",
        "- Usar ColumnTransformer para aplicar los pipelines al DataFrame"
      ],
      "metadata": {
        "id": "PSOmYyV3CAqt"
      },
      "id": "PSOmYyV3CAqt"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Identificar columnas en base al dtype"
      ],
      "metadata": {
        "id": "zx671--0xzfX"
      },
      "id": "zx671--0xzfX"
    },
    {
      "cell_type": "code",
      "source": [
        "# Datos numericos\n",
        "num_cols = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
        "print(\"Numeric features:\", num_cols)\n",
        "\n",
        "# Datos categoricos\n",
        "cat_cols = X.select_dtypes(include=[\"category\"]).columns.tolist()\n",
        "print(\"\\nCategorical features:\", cat_cols)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kU_JcFDaxLl4",
        "outputId": "e49bd2e8-d70b-4a1b-e0c5-834f2beb54d9"
      },
      "id": "kU_JcFDaxLl4",
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numeric features: ['year', 'selling_price', 'potencia_motor_hp', 'nivel_seguridad', 'eficiencia_km_l']\n",
            "\n",
            "Categorical features: ['transmission', 'tipo_carroceria', 'brand']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Construir el pipeline numerico"
      ],
      "metadata": {
        "id": "4h0v9hENyWIX"
      },
      "id": "4h0v9hENyWIX"
    },
    {
      "cell_type": "code",
      "source": [
        "num_pipe = Pipeline([\n",
        "    # Definiendo tecnicas de defensive programming\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\")), # Imputacion de media\n",
        "    (\"scaler\", StandardScaler())                   # Standard scaling\n",
        "])"
      ],
      "metadata": {
        "id": "vepTzJLPyYXG"
      },
      "id": "vepTzJLPyYXG",
      "execution_count": 250,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- El objetivo de la funcion `SimpleImputer()` es remplazar valores faltantes por el valor definido por su argumento (e.g. median).\n",
        "- El objetivo de la funcion `StandardScaler()` es que despues de una imputacion, el valor numerico es escalado para tener una media = 0 y standard deviation = 1. De esta forma se evitan posibles errores generados por tener diferentes escalas de numeros en las diferentes columnas."
      ],
      "metadata": {
        "id": "cyk6t5x1y9ad"
      },
      "id": "cyk6t5x1y9ad"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Construir el pipeline categorico"
      ],
      "metadata": {
        "id": "A-TcmKaA0xQd"
      },
      "id": "A-TcmKaA0xQd"
    },
    {
      "cell_type": "code",
      "source": [
        "cat_pipe = Pipeline([\n",
        "    # Definiendo tecnicas de defensive programming\n",
        "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),  # Imputacion de moda\n",
        "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))    # One-hot encoding\n",
        "])"
      ],
      "metadata": {
        "id": "5WypSVy705LP"
      },
      "id": "5WypSVy705LP",
      "execution_count": 251,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `SimpleImputer()` remplaza cualquier valor faltante por el valor mas frecuente (la moda). Esto preserva la distribucion del data set.\n",
        "- El objetivo del OneHotEncoder es convertir cada columna categorica en las columnas binarias necesarias para representar cada valor categorico unico.\n",
        "  - `handle_unkwnown=\"ignore\"` es util para que en caso de que aparezca una nueva categoria \"vacia\", que esta sea representada por una columna entera de puros ceros."
      ],
      "metadata": {
        "id": "3EmHAM6wBJWM"
      },
      "id": "3EmHAM6wBJWM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Implementacion de ColumnTransformer para aplicar los pipelines"
      ],
      "metadata": {
        "id": "KlPpE_hsE6D_"
      },
      "id": "KlPpE_hsE6D_"
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        # Aplicar num_pipe a las columnas numericas\n",
        "        (\"nums\", num_pipe, num_cols),\n",
        "        # Aplicar cat_pipe a columnas categoricas\n",
        "        (\"cats\", cat_pipe, cat_cols)\n",
        "    ],\n",
        "    remainder=\"drop\" # Tirar cualquier columna no listada\n",
        ")"
      ],
      "metadata": {
        "id": "a1xq23TBFJSe"
      },
      "id": "a1xq23TBFJSe",
      "execution_count": 252,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `transformers` es un array de tuples `(name, pipeline, columns)` que ira siendo populado mientras `.fit()` corre\n",
        "  1. `(\"nums\", num_pipe, num_cols)` toma todas las columnas en `num_cols` y aplica el pipeline `num_pipe` y entraga como output el array numerico transformado.\n",
        "  2. `(\"cats\", cat_pipe, cat_cols)` toma todas las columnas en `cat_cols` y aplica el pipeline `cat_pipe` y entraga como output el array categorico transformado."
      ],
      "metadata": {
        "id": "kl43BKMVJVR3"
      },
      "id": "kl43BKMVJVR3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Inspeccionar el output transformado"
      ],
      "metadata": {
        "id": "q3596Gl4KnfD"
      },
      "id": "q3596Gl4KnfD"
    },
    {
      "cell_type": "code",
      "source": [
        "# Testear el preprocessor\n",
        "preprocessor.fit(X_train)\n",
        "\n",
        "# Ver la forma del array final\n",
        "X_train_transformed = preprocessor.transform(X_train)\n",
        "print(\"Transformed shape:\", X_train_transformed.shape)\n",
        "#print(len(num_cols))\n",
        "\n",
        "# Imprimir las columnas finales\n",
        "feature_names = preprocessor.get_feature_names_out()\n",
        "print(\"All output features:\\n\", feature_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7F5TjTMKufV",
        "outputId": "97916578-1688-48ba-f354-610154119606"
      },
      "id": "z7F5TjTMKufV",
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformed shape: (8000, 41)\n",
            "All output features:\n",
            " ['nums__year' 'nums__selling_price' 'nums__potencia_motor_hp'\n",
            " 'nums__nivel_seguridad' 'nums__eficiencia_km_l' 'cats__transmission_0'\n",
            " 'cats__transmission_1' 'cats__tipo_carroceria_1'\n",
            " 'cats__tipo_carroceria_2' 'cats__tipo_carroceria_3'\n",
            " 'cats__tipo_carroceria_4' 'cats__tipo_carroceria_5'\n",
            " 'cats__brand_ambassador' 'cats__brand_audi' 'cats__brand_bmw'\n",
            " 'cats__brand_chevrolet' 'cats__brand_daewoo' 'cats__brand_datsun'\n",
            " 'cats__brand_fiat' 'cats__brand_force' 'cats__brand_ford'\n",
            " 'cats__brand_honda' 'cats__brand_hyundai' 'cats__brand_isuzu'\n",
            " 'cats__brand_jaguar' 'cats__brand_jeep' 'cats__brand_kia'\n",
            " 'cats__brand_land' 'cats__brand_mahindra' 'cats__brand_maruti'\n",
            " 'cats__brand_mercedes-benz' 'cats__brand_mg' 'cats__brand_mitsubishi'\n",
            " 'cats__brand_nissan' 'cats__brand_opelcorsa' 'cats__brand_renault'\n",
            " 'cats__brand_skoda' 'cats__brand_tata' 'cats__brand_toyota'\n",
            " 'cats__brand_volkswagen' 'cats__brand_volvo']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Lo que esto nos dice\n",
        "- En total hay 28 columnas ya con los pipelines aplicados (8 numericas y 20 categoricas) - temporal (falta agregar \"brand\" y talvez \"submodel\")\n",
        "- Los prefijos `nums_` y `cats_` nos dicen de cual pipeline proviene cada columna\n",
        "- Estos nombres nos serviran despues para implementacion de funciones o debugging"
      ],
      "metadata": {
        "id": "SZumUwvGMuMR"
      },
      "id": "SZumUwvGMuMR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression\n",
        "- La regresi√≥n log√≠stica es una t√©cnica de an√°lisis de datos que utiliza las matem√°ticas para encontrar las relaciones entre dos factores de datos. Luego, utiliza esta relaci√≥n para predecir el valor de uno de esos factores bas√°ndose en el otro. Normalmente, la predicci√≥n tiene un n√∫mero finito de resultados, como un s√≠ o un no."
      ],
      "metadata": {
        "id": "H2t9M4f-R5j2"
      },
      "id": "H2t9M4f-R5j2"
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un objecto de LogisticRegression\n",
        "logreg = LogisticRegression(\n",
        "    multi_class=\"multinomial\",   # Clasificacion multiclase\n",
        "    solver=\"saga\",               # Algoritmo de optimizacion (soporta L1/L2)\n",
        "    class_weight=\"balanced\",     # Ajuste de pesos para clases desbalanceadas\n",
        "    max_iter=1000,               # Numero maximo de iteraciones\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Construir un unico pipeline\n",
        "lr_pipeline = Pipeline([\n",
        "    (\"preprocessor\", preprocessor),\n",
        "    (\"classifier\", logreg)\n",
        "])\n",
        "\n",
        "# Usar 5-fold cross-validation para evaluar el modelo de regresion logistica\n",
        "cv_macro_f1 = cross_val_score(\n",
        "    lr_pipeline,    # Pipeline completeo\n",
        "    X,              # Todas las features\n",
        "    y,              # Todas las labels\n",
        "    cv=5,           # 5 folds\n",
        "    scoring=\"f1_macro\", # macro-averaged F1\n",
        "    n_jobs=-1       # Usar todos los nucleos del CPU\n",
        ")\n",
        "\n",
        "# Imprimir los fold scores y la media\n",
        "print(\"Logistic Regression 5-fold CV macro-F1 scores:\", cv_macro_f1.round(4))\n",
        "print(\"Mean macro-F1:\", cv_macro_f1.mean().round(4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSvhbZ08R-Ig",
        "outputId": "b0882698-1852-4205-b0f6-c0fc6580e7b0"
      },
      "id": "wSvhbZ08R-Ig",
      "execution_count": 254,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression 5-fold CV macro-F1 scores: [0.9295 0.911  0.9005 0.8691 0.8722]\n",
            "Mean macro-F1: 0.8964\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Entendiendo la media Macro-F1\n",
        "- La evaluacion multiclase Macro-F1 toma el promedio no ponderado de los tres puntajes F1 por clase (\"Alta\", \"Media\", \"Baja\"). Este proceso toma cada clase de forma equivalente aunque la distribucion sea diferente (10.5%, 84%, 5.5%). Usando macro-F1 nos aseguramos de que el modelo no esta eligiendo \"Media\" en todas las predicciones y realmente esta prediciendo entre las tres clases.\n",
        "- El metodo de evaluacion 5-fold cross-validation es una manera de estimar que tan bien el pipeline (preprocessor + modelo) se generaliza a datasets no vistos\n",
        "  - Se divide el dataset completo entre 5 subsets (folds), en este caso cada fold tiene aproximadamente 2000 carros.\n",
        "  - Al final obtenemos 5 scores, una por cada subset, esto en toeria refleja que tan bien se comportaria el pipeline si fuera un \"nuevo\" dataset. El promedio de esas 5 scores es lo que llamamos mean macro-F1."
      ],
      "metadata": {
        "id": "53QQETV7uJtP"
      },
      "id": "53QQETV7uJtP"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Lo que los resulatados del Macro-F1 nos dicen\n",
        "- Los 5 scores estan arribe de 0.90, lo que quiere decir que el pipeline esta consistentemente obteniendo un score alto en \"nueva\" informacion.\n",
        "- La media macro-F1 de 0.9274 es el mejor resumen num√©rico del \"rendimiento esperado\" si se entren√≥ con el 80 % del conjunto de datos y se prob√≥ con el 20 % restante. Esto sugiere que, en promedio, el modelo clasifica correctamente casi todos los ejemplos de \"Media\" y tambi√©n funciona bien con \"Alta\" y \"Baja\"."
      ],
      "metadata": {
        "id": "0iNV3UqJyHRt"
      },
      "id": "0iNV3UqJyHRt"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Logistic Regression Training & Testing\n"
      ],
      "metadata": {
        "id": "TydGfRBNdysi"
      },
      "id": "TydGfRBNdysi"
    },
    {
      "cell_type": "code",
      "source": [
        "# Test 1\n",
        "# Establecer split (Train/Test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,    # 80/20 split\n",
        "    stratify=y,       # preserva los ratios 84/10.5/5.5 para train y test\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Asegurarse de las columnas presentes en X_train\n",
        "print(\"Columns in X_train:\", X_train.columns.tolist())\n",
        "\n",
        "# Fit X_train, y_train (80%) y evaluar en X_test, y_test (20%)\n",
        "lr_pipeline.fit(X_train, y_train)\n",
        "y_test_pred = lr_pipeline.predict(X_test)\n",
        "\n",
        "# Evaluar el test\n",
        "test_acc = accuracy_score(y_test, y_test_pred)\n",
        "print(f\"Logistic Regression Test Accuracy: {test_acc:.4f}\")\n",
        "print(\"\\nLogistic Regression Test Classification Report:\\n\")\n",
        "print(classification_report(\n",
        "    y_test,\n",
        "    y_test_pred,\n",
        "    digits=4,         # Numero de decimales\n",
        "    zero_division=0   # Ignorar zero-division errors (debido a strings)\n",
        "))\n",
        "\n",
        "# Generar confusion matrix\n",
        "cm = confusion_matrix(y_test, y_test_pred, labels=[\"Media\",\"Alta\",\"Baja\"])\n",
        "print(\"Confusion Matrix:\\n\", cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-xrcNyzzVIZ",
        "outputId": "2c4675e5-6b13-46ef-ab39-5de9866f46fe"
      },
      "id": "1-xrcNyzzVIZ",
      "execution_count": 255,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns in X_train: ['year', 'selling_price', 'transmission', 'tipo_carroceria', 'potencia_motor_hp', 'nivel_seguridad', 'eficiencia_km_l', 'brand']\n",
            "Logistic Regression Test Accuracy: 0.9530\n",
            "\n",
            "Logistic Regression Test Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Alta     0.8434    1.0000    0.9150       210\n",
            "        Baja     0.6667    1.0000    0.8000       110\n",
            "       Media     1.0000    0.9440    0.9712      1680\n",
            "\n",
            "    accuracy                         0.9530      2000\n",
            "   macro avg     0.8367    0.9813    0.8954      2000\n",
            "weighted avg     0.9652    0.9530    0.9559      2000\n",
            "\n",
            "Confusion Matrix:\n",
            " [[1586   39   55]\n",
            " [   0  210    0]\n",
            " [   0    0  110]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test 2\n",
        "# 3.3.1 New random split\n",
        "X2_train, X2_test, y2_train, y2_test = train_test_split(\n",
        "    X, y, test_size=0.20, stratify=y, random_state=99\n",
        ")\n",
        "\n",
        "# 3.3.2 Re‚Äêfit your original pipeline (with score_calidad)\n",
        "lr_pipeline.fit(X2_train, y2_train)\n",
        "y2_pred = lr_pipeline.predict(X2_test)\n",
        "\n",
        "acc2 = accuracy_score(y2_test, y2_pred)\n",
        "print(f\"New split (seed=99) Test Accuracy: {acc2:.4f}\")\n",
        "print(\"\\nNew split Classification Report:\\n\")\n",
        "print(classification_report(y2_test, y2_pred, digits=4, zero_division=0))\n",
        "\n",
        "# Generar confusion matrix\n",
        "cm = confusion_matrix(y2_test, y2_pred, labels=[\"Media\",\"Alta\",\"Baja\"])\n",
        "print(\"Confusion Matrix:\\n\", cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNQUsmC5HPc8",
        "outputId": "d98d78c4-d523-4534-a37a-f97ea34bd1b5"
      },
      "id": "TNQUsmC5HPc8",
      "execution_count": 256,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New split (seed=99) Test Accuracy: 0.9580\n",
            "\n",
            "New split Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Alta     0.8434    1.0000    0.9150       210\n",
            "        Baja     0.7097    1.0000    0.8302       110\n",
            "       Media     1.0000    0.9500    0.9744      1680\n",
            "\n",
            "    accuracy                         0.9580      2000\n",
            "   macro avg     0.8510    0.9833    0.9065      2000\n",
            "weighted avg     0.9676    0.9580    0.9602      2000\n",
            "\n",
            "Confusion Matrix:\n",
            " [[1596   39   45]\n",
            " [   0  210    0]\n",
            " [   0    0  110]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Testing Logistic Regression"
      ],
      "metadata": {
        "id": "oQOPPp6yTVgh"
      },
      "id": "oQOPPp6yTVgh"
    },
    {
      "cell_type": "code",
      "source": [
        "# Input entry test\n",
        "lr_pipeline.fit(X_train, y_train)\n",
        "\n",
        "X.columns.tolist()\n",
        "\n",
        "new_car_data = {\n",
        "    \"year\": [2018],                   # int\n",
        "    \"selling_price\": [350000],        # int or float\n",
        "    \"km_driven\": [25000],             # int\n",
        "    \"fuel\": [1],                      # must match the same category codes you used\n",
        "    \"combustible_estimado_l\": [1800.0],  # float\n",
        "    \"seller_type\": [0],               # category code\n",
        "    \"transmission\": [1],              # category code\n",
        "    \"owner\": [0],                     # category code\n",
        "    \"tipo_carroceria\": [2],           # category code\n",
        "    \"potencia_motor_hp\": [120],       # int\n",
        "    \"nivel_seguridad\": [4.5],         # float\n",
        "    \"score_calidad\": [5.5],           # float\n",
        "    \"eficiencia_km_l\": [18.0],         # float\n",
        "    \"brand\": [\"Toyota\"]             # string; will be cast to category below\n",
        "}\n",
        "\n",
        "new_car_df = pd.DataFrame(new_car_data)\n",
        "\n",
        "cat_cols = [\"fuel\", \"seller_type\", \"transmission\", \"owner\", \"tipo_carroceria\", \"brand\"]\n",
        "for col in cat_cols:\n",
        "    new_car_df[col] = new_car_df[col].astype(\"category\")\n",
        "\n",
        "# new_car_df[\"brand\"] = new_car_df[\"brand\"].astype(\"category\")\n",
        "\n",
        "print(new_car_df.dtypes)\n",
        "\n",
        "predicted_label = lr_pipeline.predict(new_car_df)\n",
        "print(\"\\nPredicted calidad_auto:\", predicted_label[0])\n",
        "\n",
        "predicted_proba = lr_pipeline.predict_proba(new_car_df)\n",
        "print(\"Predicted probabilities [Alta, Media, Baja]:\", predicted_proba[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Erwroz9ed6i4",
        "outputId": "724e756a-374b-4d2c-db83-ded7c4121264"
      },
      "id": "Erwroz9ed6i4",
      "execution_count": 257,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "year                         int64\n",
            "selling_price                int64\n",
            "km_driven                    int64\n",
            "fuel                      category\n",
            "combustible_estimado_l     float64\n",
            "seller_type               category\n",
            "transmission              category\n",
            "owner                     category\n",
            "tipo_carroceria           category\n",
            "potencia_motor_hp            int64\n",
            "nivel_seguridad            float64\n",
            "score_calidad              float64\n",
            "eficiencia_km_l            float64\n",
            "brand                     category\n",
            "dtype: object\n",
            "\n",
            "Predicted calidad_auto: Alta\n",
            "Predicted probabilities [Alta, Media, Baja]: [9.99999991e-01 1.38171057e-25 9.08181966e-09]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest\n",
        "- Random Forest es un algoritmo de aprendizaje supervisado en machine learning que utiliza m√∫ltiples √°rboles de decisi√≥n para clasificar o predecir datos. Es un m√©todo de conjunto (ensemble method) que mejora la precisi√≥n de las predicciones combinando los resultados de varios modelos d√©biles (√°rboles de decisi√≥n)."
      ],
      "metadata": {
        "id": "GH-jnMM-gSKE"
      },
      "id": "GH-jnMM-gSKE"
    },
    {
      "cell_type": "code",
      "source": [
        "# Establecer split (Train/Test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,    # 80/20 split\n",
        "    stratify=y,       # preserva los ratios 84/10.5/5.5 para train y test\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Construir e inicializar un RandomForestClassifer\n",
        "rf_clf = RandomForestClassifier(\n",
        "    n_estimators=300,     # Numero de arboles en el bosque\n",
        "    max_depth=None,       # Profundidad maxima de los arboles\n",
        "    class_weight=\"balanced\",  # Ajuste de pesos para clases desbalanceadas\n",
        "    min_samples_split=2,  # Minimo numero de muestras requeridas para dividir\n",
        "    random_state=42,      # Seed\n",
        "    n_jobs=-1             # Usar todos los nucleos del CPU\n",
        ")\n",
        "\n",
        "# Crear un Pipeline unico que aplica el preprocessor previamente definido\n",
        "rf_pipeline = Pipeline([\n",
        "    # Usando el preprocessor que definimos previamente (ColumnTransformer)\n",
        "    (\"preprocessor\", preprocessor),\n",
        "    (\"classifier\", rf_clf)\n",
        "])"
      ],
      "metadata": {
        "id": "58rnhuodgpHZ"
      },
      "id": "58rnhuodgpHZ",
      "execution_count": 258,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `n_estimators=300` construye 300 arbholes de decision\n",
        "- `class_weight=\"balanced\"` garantiza que las clases minoritarias tengan mayor ponderacion durante las divisiones\n",
        "- `n_jobs=-1` paraleliza la construccion de arboles en todos los nucleos\n",
        "- Reutilizamos el mismo preprocesador que gestiona la imputacion de la mediana, el escalado y el One-hot encoding. De esta forma, Random Forest ve la misma matriz numerica de 28 columnnas.."
      ],
      "metadata": {
        "id": "FlPbXasikWaP"
      },
      "id": "FlPbXasikWaP"
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar las columnas consideradas\n",
        "print(\"Features in X:\", X.columns.tolist())\n",
        "\n",
        "# if \"score_calidad\" in X.columns:\n",
        "#     X = X.drop(columns=[\"score_calidad\"])\n",
        "# if \"calidad_code\" in X.columns:\n",
        "#     X = X.drop(columns=[\"calidad_code\"])\n",
        "\n",
        "# Usar 5-fold cross-validation para evaluar el Random Forest\n",
        "rf_cv_scores = cross_val_score(\n",
        "    rf_pipeline,\n",
        "    X,            # full feature set\n",
        "    y,            # full labels\n",
        "    cv=5,\n",
        "    scoring=\"f1_macro\",\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Imprimir scores del 5-fold test\n",
        "print(\"Random Forest 5-fold CV macro-F1 scores:\", rf_cv_scores.round(4))\n",
        "print(\"Mean macro-F1 (RF):\", rf_cv_scores.mean().round(4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tJEf46_lHaE",
        "outputId": "ab6ee380-9906-43ee-c553-8a7cd4951fd5"
      },
      "id": "4tJEf46_lHaE",
      "execution_count": 259,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features in X: ['year', 'selling_price', 'transmission', 'tipo_carroceria', 'potencia_motor_hp', 'nivel_seguridad', 'eficiencia_km_l', 'brand']\n",
            "Random Forest 5-fold CV macro-F1 scores: [0.807  0.9036 0.9072 0.8987 0.8769]\n",
            "Mean macro-F1 (RF): 0.8787\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Lo que los resulatados del Macro-F1 nos dicen\n",
        "- Los 5 scores son relativamente altos, lo que quiere decir que el pipeline esta consistentemente obteniendo un score alto en \"nueva\" informacion. Sinembargo, parece que el modelo es algo sensible dependeindo de cual 20% es escogido.\n",
        "- Comparado a al modelo de Regresion Logistica, que tuvo un macro-F1 de 0.909 (ignorando la columna \"score_calidad\"), el modelo de Random Forest de hecho so comporta un poco peor en el 5-fold test. Esto puede significar que los limites lineales aprendidos por la regresion logistica eran mas precisos al momento de separar \"Alta\"/\"Media\"/\"Baja\" que el Random Forest."
      ],
      "metadata": {
        "id": "yRE3aAuU3Jbv"
      },
      "id": "yRE3aAuU3Jbv"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Random Forest Training and Testing"
      ],
      "metadata": {
        "id": "lhxAYLfVnMj_"
      },
      "id": "lhxAYLfVnMj_"
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit Random Forest pipeline\n",
        "rf_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predecir en el split de 20%\n",
        "y_rf_pred = rf_pipeline.predict(X_test)\n",
        "\n",
        "# Evaluar el modelo\n",
        "rf_test_acc = accuracy_score(y_test, y_rf_pred)\n",
        "print(f\"Random Forest Test Accuracy: {rf_test_acc:.4f}\")\n",
        "\n",
        "# Classification report\n",
        "print(\"\\nRandom Forest Classification Report (Test Set):\\n\")\n",
        "print(classification_report(\n",
        "    y_test,\n",
        "    y_rf_pred,\n",
        "    digits=4,\n",
        "    zero_division=0\n",
        "))\n",
        "\n",
        "# Confusion matrix\n",
        "rf_cm = confusion_matrix(y_test, y_rf_pred, labels=[\"Media\", \"Alta\", \"Baja\"])\n",
        "print(\"\\nRandom Forest Confusion Matrix (Test Set):\\n\", rf_cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nuip_xlsnAUV",
        "outputId": "2396b68e-4a15-4d5b-b076-3c99fd965e6e"
      },
      "id": "Nuip_xlsnAUV",
      "execution_count": 260,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Test Accuracy: 0.9635\n",
            "\n",
            "Random Forest Classification Report (Test Set):\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Alta     0.9620    0.8429    0.8985       210\n",
            "        Baja     0.9639    0.7273    0.8290       110\n",
            "       Media     0.9636    0.9940    0.9786      1680\n",
            "\n",
            "    accuracy                         0.9635      2000\n",
            "   macro avg     0.9632    0.8547    0.9020      2000\n",
            "weighted avg     0.9635    0.9635    0.9620      2000\n",
            "\n",
            "\n",
            "Random Forest Confusion Matrix (Test Set):\n",
            " [[1670    7    3]\n",
            " [  33  177    0]\n",
            " [  30    0   80]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Test 2\n",
        "X2_train, X2_test, y2_train, y2_test = train_test_split(\n",
        "    X, y, test_size=0.20, stratify=y, random_state=99\n",
        ")\n",
        "rf_clf2 = RandomForestClassifier(\n",
        "    n_estimators=300,\n",
        "    max_depth=None,\n",
        "    class_weight=\"balanced\",\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "rf_pipeline2 = Pipeline([\n",
        "    (\"preprocessor\", preprocessor),\n",
        "    (\"classifier\", rf_clf2)\n",
        "])\n",
        "rf_pipeline2.fit(X2_train, y2_train)\n",
        "y2_pred = rf_pipeline2.predict(X2_test)\n",
        "acc2 = accuracy_score(y2_test, y2_pred)\n",
        "print(\"New-split Test Accuracy:\", acc2)\n",
        "print(classification_report(y2_test, y2_pred, digits=4, zero_division=0))\n",
        "\n",
        "# Confusion matrix\n",
        "rf_cm = confusion_matrix(y2_test, y2_pred, labels=[\"Media\", \"Alta\", \"Baja\"])\n",
        "print(\"\\nRandom Forest Confusion Matrix (Test Set):\\n\", rf_cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h27-Swu2sn5G",
        "outputId": "c797a6b1-cf8e-49c8-a9f9-b5536418d4b8"
      },
      "id": "h27-Swu2sn5G",
      "execution_count": 261,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New-split Test Accuracy: 0.9565\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Alta     0.9503    0.8190    0.8798       210\n",
            "        Baja     0.9375    0.6818    0.7895       110\n",
            "       Media     0.9580    0.9917    0.9746      1680\n",
            "\n",
            "    accuracy                         0.9565      2000\n",
            "   macro avg     0.9486    0.8308    0.8813      2000\n",
            "weighted avg     0.9561    0.9565    0.9544      2000\n",
            "\n",
            "\n",
            "Random Forest Confusion Matrix (Test Set):\n",
            " [[1666    9    5]\n",
            " [  38  172    0]\n",
            " [  35    0   75]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Boosted Tree (LightGBM)\n",
        "- LightGBM es un marco de trabajo de refuerzo de gradiente r√°pido, distribuido y de alto rendimiento que utiliza un algoritmo de aprendizaje basado en √°rboles. Est√° dise√±ado espec√≠ficamente para grandes conjuntos de datos y datos de alta dimensi√≥n, y ofrece ventajas como mayor velocidad de entrenamiento, menor uso de memoria y mayor precisi√≥n en comparaci√≥n con otros algoritmos de refuerzo. Los √°rboles reforzados, en general, son un m√©todo de aprendizaje conjunto que combina m√∫ltiples aprendices d√©biles (como √°rboles de decisi√≥n) para crear un modelo predictivo s√≥lido."
      ],
      "metadata": {
        "id": "YucJcX9L5fpB"
      },
      "id": "YucJcX9L5fpB"
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir un pipeline de LGBM\n",
        "lgbm_clf = lgb.LGBMClassifier(\n",
        "    objective=\"multiclass\",\n",
        "    class_weight=\"balanced\",\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "lgbm_pipeline = Pipeline([\n",
        "    # Usando el preprocessor que definimos previamente (ColumnTransformer)\n",
        "    (\"preprocessor\", preprocessor),\n",
        "    (\"classifier\", lgbm_clf)\n",
        "])\n",
        "\n",
        "# Usar 5-fold cross-validation para evaluar el LightGBM\n",
        "lgbm_cv_scores = cross_val_score(\n",
        "    lgbm_pipeline,\n",
        "    X,\n",
        "    y,\n",
        "    cv=5,\n",
        "    scoring=\"f1_macro\",\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Imprimir scores del 5-fold test\n",
        "print(\"LightGBM 5-fold CV macro-F1:\", lgbm_cv_scores.round(4))\n",
        "print(\"Mean macro-F1 (LGBM):\", lgbm_cv_scores.mean().round(4))"
      ],
      "metadata": {
        "id": "tuKhuqdh6Pc7",
        "outputId": "1d298266-a26a-419f-bac4-ddabdf66b9da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "tuKhuqdh6Pc7",
      "execution_count": 262,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LightGBM 5-fold CV macro-F1: [0.9414 0.941  0.9466 0.9301 0.9222]\n",
            "Mean macro-F1 (LGBM): 0.9363\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Lo que los resulatados del Macro-F1 nos dicen\n",
        "- Los 5 scores son muy altos, lo que quiere decir que el pipeline esta consistentemente obteniendo un score alto en \"nueva\" informacion. El pipeline generaliza muy bien cada 20% del dataset\n",
        "- Este modelo representa una mejora ante los dos modelos implementados previamente\n",
        "  - Regresion Logistica (sin \"score_calidad\"): media CV macro-F1 ‚âà 0.909\n",
        "  - Random Forest (sin \"score_calidad\"): media CV macro-F1 ‚âà 0.8613\n",
        "- Hasta este punto el modelo de LightGBM tiene el mejor rendimiento categorizando el dataset y prediciendo \"calidad_auto\""
      ],
      "metadata": {
        "id": "sDfrYaVlC_NH"
      },
      "id": "sDfrYaVlC_NH"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### LightGBM testing"
      ],
      "metadata": {
        "id": "rGl8oDi381Dg"
      },
      "id": "rGl8oDi381Dg"
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit LGBM pipeline en el split de 80%\n",
        "lgbm_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predecir en el split de 20%\n",
        "y_lgbm_pred = lgbm_pipeline.predict(X_test)\n",
        "\n",
        "# Evaluar el modelo\n",
        "lgbm_test_acc = accuracy_score(y_test, y_lgbm_pred)\n",
        "print(f\"\\nLightGBM Test Accuracy: {lgbm_test_acc:.4f}\")\n",
        "\n",
        "# Classification report\n",
        "print(\"\\nLightGBM Report (Test Set):\\n\")\n",
        "print(classification_report(\n",
        "    y_test,\n",
        "    y_lgbm_pred,\n",
        "    digits=4,\n",
        "    zero_division=0\n",
        "))\n",
        "\n",
        "# Confusion matrix\n",
        "lgbm_cm = confusion_matrix(y_test, y_lgbm_pred, labels=[\"Media\", \"Alta\", \"Baja\"])\n",
        "print(\"\\nRandom Forest Confusion Matrix (Test Set):\\n\", lgbm_cm)"
      ],
      "metadata": {
        "id": "SFZBU2cw84HN",
        "outputId": "037d4c42-ea11-4028-8c78-015ba47e7082",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "SFZBU2cw84HN",
      "execution_count": 263,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000430 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 872\n",
            "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 30\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "\n",
            "LightGBM Test Accuracy: 0.9755\n",
            "\n",
            "LightGBM Report (Test Set):\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Alta     0.9349    0.9571    0.9459       210\n",
            "        Baja     0.8333    0.9545    0.8898       110\n",
            "       Media     0.9916    0.9792    0.9853      1680\n",
            "\n",
            "    accuracy                         0.9755      2000\n",
            "   macro avg     0.9199    0.9636    0.9403      2000\n",
            "weighted avg     0.9769    0.9755    0.9759      2000\n",
            "\n",
            "\n",
            "Random Forest Confusion Matrix (Test Set):\n",
            " [[1645   14   21]\n",
            " [   9  201    0]\n",
            " [   5    0  105]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Boosted Tree (XGBoost)\n",
        "- XGBoost es una potente biblioteca de aprendizaje autom√°tico de c√≥digo abierto que utiliza el aumento de gradiente para crear modelos predictivos de alta precisi√≥n. Es conocida por su velocidad, eficiencia y capacidad para gestionar grandes conjuntos de datos. XGBoost es especialmente √∫til para tareas de clasificaci√≥n y regresi√≥n, y se utiliza a menudo en competiciones de aprendizaje autom√°tico debido a su excelente rendimiento."
      ],
      "metadata": {
        "id": "Ch3eDLKRVGgw"
      },
      "id": "Ch3eDLKRVGgw"
    },
    {
      "cell_type": "code",
      "source": [
        "# Constuir un pipelien de XGBBoost\n",
        "xgb_clf = XGBClassifier(\n",
        "    objective=\"multi:softprob\",   # objetivo multiclase\n",
        "    num_class=3,                  # 3 clases: Alta, Media, Baja\n",
        "    learning_rate=0.1,            # Tasa de aprendizaje\n",
        "    n_estimators=200,             # Numero de arboles\n",
        "    max_depth=6,                  # Profundidad de cada arbol\n",
        "    subsample=0.8,                # Porcentaje de muestras\n",
        "    colsample_bytree=0.8,         # Porcentaje de features\n",
        "    scale_pos_weight=1,           # Balanceo de clases\n",
        "    random_state=42,              # Seed\n",
        "    n_jobs=-1                     # Usar todos los nucleos del CPU\n",
        ")\n",
        "\n",
        "xgb_pipeline = Pipeline([\n",
        "    # Usando el preprocessor que definimos previamente (ColumnTransformer)\n",
        "    (\"preprocessor\", preprocessor),\n",
        "    (\"classifier\", xgb_clf)\n",
        "])\n",
        "\n",
        "# XGBoost requiere etiquetas en formato entero (no en string)\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "# Ahora y_encoded contiene {0, 1, 2} correspondiendo a [\"Alta\", \"Baja\", \"Media\"]\n",
        "\n",
        "# Usar 5-fold cross-validation para evaluar XGBoost\n",
        "xgb_cv_scores = cross_val_score(\n",
        "    xgb_pipeline,\n",
        "    X,\n",
        "    y_encoded,\n",
        "    cv=5,\n",
        "    scoring=\"f1_macro\",\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Imprimir scores del 5-fold test\n",
        "print(\"XGBoost 5-fold CV macro-F1:\", xgb_cv_scores.round(4))\n",
        "print(\"Mean macro-F1 (XGBoost):\", xgb_cv_scores.mean().round(4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8XL0g-AV2FB",
        "outputId": "262be0d1-f43d-41ac-8588-64cf8bcf99ea"
      },
      "id": "c8XL0g-AV2FB",
      "execution_count": 264,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost 5-fold CV macro-F1: [0.9107 0.9561 0.9513 0.9329 0.932 ]\n",
            "Mean macro-F1 (XGBoost): 0.9366\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Explicaci√≥n de los parametros\n",
        "- `n_estimator=200` y `max_depth=6` son estandards de rango medio que funcionan con frecuencia.\n",
        "- `subsample=0.8` y `colsample_bytree=0.8` agregan ensacado a nivel de fila y columna para reducir el sobreajuste.\n",
        "- No pasamos directamente un `class_weight` a XGBClassifier, en su lugar, XGBoost usa `scale_pos_weight` solo para la clasficaci√≥n binaria. Para multiclase lo dejamos en 1 y nos basamos en el muestreo balanceado mediante la division estratificada de la canalizaci√≥n.\n",
        "\n",
        "##### Nota sobre la codificai√≥n de etiquetas\n",
        "- `LabelEncoder` toma las clases de tipo string `[\"Alta\",\"Baja\",\"Media\"]` y las mapea a valores enteros `[0,1,2]` (por defecto en orden alfabetico: ‚ÄúAlta‚Äù‚Üí0, ‚ÄúBaja‚Äù‚Üí1, ‚ÄúMedia‚Äù‚Üí2)\n",
        "- `cross_val_score(..., y_encoded, ...)` satisface los requerimientos de XGBoost.\n",
        "\n",
        "##### Lo que los resulatados del Macro-F1 nos dicen\n",
        "- Al colocar aleatoriamente el 20 % de los 10,000 carros de cinco maneras diferentes, XGBoost promedia alrededor del 93,62 % de macro-F1, mejor que todos los modelos anteriores. Esto sugiere que XGBoost captura las sutiles interacciones no lineales entre las caracter√≠sticas con una eficacia ligeramente superior a la de LightGBM.\n",
        "  - Logistic (sin `score_calidad`): ‚âà 0.909\n",
        "  - Random Forest (sin `score_calidad`): ‚âà 0.8613\n",
        "  - LightGBM (sin `score_calidad`): ‚âà 0.9335\n",
        "  - XGBoost (sin `score_calidad`): ‚âà 0.9362"
      ],
      "metadata": {
        "id": "d1tKnyqEbSiE"
      },
      "id": "d1tKnyqEbSiE"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### XGBoost testing"
      ],
      "metadata": {
        "id": "_e4d5g3ic76y"
      },
      "id": "_e4d5g3ic76y"
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-codificar los splits de entrenamiento\n",
        "y_train_enc = le.transform(y_train)\n",
        "y_test_enc  = le.transform(y_test)\n",
        "\n",
        "# Fit XGBoost pipeline en el split de 80%\n",
        "xgb_pipeline.fit(X_train, y_train_enc)\n",
        "\n",
        "# Predecir en el split de 20%\n",
        "y_xgb_pred_enc = xgb_pipeline.predict(X_test)\n",
        "y_xgb_pred = le.inverse_transform(y_xgb_pred_enc) # Decodifica las predicciones\n",
        "\n",
        "# Evaluar el modelo\n",
        "xgb_test_acc = accuracy_score(y_test, y_xgb_pred)\n",
        "print(f\"XGBoost Test Accuracy: {xgb_test_acc:.4f}\")\n",
        "\n",
        "# Classification report\n",
        "print(\"\\nXGBoost Classification Report (Test Set):\\n\")\n",
        "print(classification_report(\n",
        "    y_test,\n",
        "    y_xgb_pred,\n",
        "    digits=4,\n",
        "    zero_division=0\n",
        "))\n",
        "\n",
        "# Confusion matrix\n",
        "xgb_cm = confusion_matrix(y_test, y_xgb_pred, labels=[\"Media\", \"Alta\", \"Baja\"])\n",
        "print(\"\\nXGBoost Confusion Matrix (Test Set):\\n\", xgb_cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMdln4mQc1fB",
        "outputId": "02d231b6-b489-4d55-f44e-a2e07f626a6d"
      },
      "id": "CMdln4mQc1fB",
      "execution_count": 265,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Test Accuracy: 0.9800\n",
            "\n",
            "XGBoost Classification Report (Test Set):\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Alta     0.9747    0.9190    0.9461       210\n",
            "        Baja     0.9694    0.8636    0.9135       110\n",
            "       Media     0.9812    0.9952    0.9882      1680\n",
            "\n",
            "    accuracy                         0.9800      2000\n",
            "   macro avg     0.9751    0.9260    0.9492      2000\n",
            "weighted avg     0.9799    0.9800    0.9796      2000\n",
            "\n",
            "\n",
            "XGBoost Confusion Matrix (Test Set):\n",
            " [[1672    5    3]\n",
            " [  17  193    0]\n",
            " [  15    0   95]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Interpretando los resultados de XGBoost\n",
        "Precisi√≥n general = 0,9770\n",
        "- De los 2000 coches del split, XGBoost clasific√≥ correctamente 1954 (‚âà 97,7 %). Esto es superior al ‚âà 97,55 % de LightGBM y al ‚âà 96,15 % de Logistic Regression, asi como al Random Forest.\n",
        "\n",
        "Precisi√≥n por clase / Recall / F1\n",
        "1. ‚ÄúAlta‚Äù (210 ejemplos)\n",
        "  - Precisi√≥n = 0,9742: De todos los carros que XGBoost predijo ‚ÄúAlta‚Äù, el 97,42 % eran realmente Alta (es decir, pocos falsos positivos de Alta).\n",
        "  - Recall = 0,9000: El 90 % de los carros Alta reales se detectaron correctamente (es decir, el 10 % de los Alta se etiquetaron err√≥neamente como ‚ÄúMedia‚Äù).\n",
        "  - F1 = 0,9356: La media arm√≥nica que equilibra el recall de 0,90 y la precisi√≥n de 0,9742.\n",
        "\n",
        "  - De la segunda fila de la matriz de confusi√≥n (`[ 21 189 0 ]`), XGBoost etiquet√≥ correctamente 189 de los 210 carros Alta; 21 Alta se predijeron como Media (ninguno como Baja).\n",
        "\n",
        "2. ‚ÄúBaja‚Äù (110 ejemplos)\n",
        "  - Precisi√≥n = 0,9592: El 95,92 % de todo lo que se predijo como ‚ÄúBaja‚Äù en realidad era Baja.\n",
        "  - Recall = 0,8545: Se detect√≥ correctamente el 85,45 % de los 110 carros Baja reales; el 14,55 % restante (‚âà 16 carros) se etiquet√≥ err√≥neamente como Media.\n",
        "  - F1 = 0,9038.\n",
        "  - La tercera fila de la matriz de confusi√≥n (`[16 0 94]`): 94/110 Baja predijeron correctamente; 16 Baja se clasificaron err√≥neamente como Media.\n",
        "\n",
        "3. ‚ÄúMedia‚Äù (1680 ejemplos)\n",
        "  - Precisi√≥n = 0,9783: De todos los veh√≠culos etiquetados como ‚ÄúMedia‚Äù, el 97,83 % lo fue realmente.\n",
        "  - Recall = 0,9946: Se detect√≥ correctamente el 99,46 % de los 1680 veh√≠culos Media; solo ‚âà 9 fueron mal etiquetados (5 como Alta, 4 como Baja).\n",
        "  - F1 = 0,9864.\n",
        "  En la primera fila de la matriz de confusi√≥n (`[1671 5 4]`): 1671/1680 Media predijeron correctamente, 5 se clasificaron err√≥neamente como Alta, 4 como Baja."
      ],
      "metadata": {
        "id": "Qcersptttgrl"
      },
      "id": "Qcersptttgrl"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Hyperparameter Tunning for XGBoost"
      ],
      "metadata": {
        "id": "roeE397pvk4L"
      },
      "id": "roeE397pvk4L"
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir el espacio de busqueda de los hiperparametros\n",
        "param_dist_xgb = {  # El estimador de XGBoost se llama \"classifier\"\n",
        "    \"classifier__learning_rate\": [0.01, 0.05, 0.1],\n",
        "    \"classifier__n_estimators\": [100, 200, 400],\n",
        "    \"classifier__max_depth\": [4, 6, 8],\n",
        "    \"classifier__subsample\": [0.6, 0.8, 1.0],\n",
        "    \"classifier__colsample_bytree\": [0.6, 0.8, 1.0]\n",
        "}\n",
        "\n",
        "# Llevar a cabo una busqueda de hiperparametros randomizada en el diccionario\n",
        "xgb_search = RandomizedSearchCV(\n",
        "    xgb_pipeline,       # El estimador siendo tuneado\n",
        "    param_dist_xgb,     # El diccionario que definimos\n",
        "    n_iter=20,          # N diferentes combinaciones de parametros\n",
        "    cv=3,               # Usar 3-fold cross validation (80/20/20)\n",
        "    scoring=\"f1_macro\", # Criteria a ser evaluada\n",
        "    random_state=42,    # Seed\n",
        "    n_jobs=-1           # Usar todos los nucleos del CPU\n",
        ")\n",
        "\n",
        "# Correr el randomized search (20 veces en total)\n",
        "xgb_search.fit(X_train, y_train_enc)\n",
        "\n",
        "# Imprimir los hiperparametros encontrados y los scores del CV\n",
        "print(\"Best XGBoost params:\", xgb_search.best_params_)\n",
        "print(\"Best CV macro-F1 (XGB):\", xgb_search.best_score_.round(4))\n",
        "\n",
        "# Evaluar el modelo entero (preprocessor + XGBClassifier)\n",
        "best_xgb = xgb_search.best_estimator_\n",
        "y_tuned_pred_enc = best_xgb.predict(X_test)\n",
        "\n",
        "# Decodificar resultados\n",
        "y_best_xgb_str = le.inverse_transform(y_tuned_pred_enc)\n",
        "\n",
        "# Imprimir macro-F1 score\n",
        "test_macro_f1 = f1_score(y_test, y_best_xgb_str, average=\"macro\")\n",
        "print(\"Tuned XGBoost Test macro-F1:\", test_macro_f1)\n",
        "\n",
        "# Imprimir accuracy del modelo\n",
        "tun_xgb_test_acc = accuracy_score(y_test, y_best_xgb_str)\n",
        "print(f\"XGBoost Test Accuracy: {tun_xgb_test_acc:.4f}\")\n",
        "\n",
        "# Classification report\n",
        "print(\"\\nTuned XGBoost Classification Report (Test Set):\\n\")\n",
        "print(classification_report(\n",
        "    y_test,\n",
        "    y_best_xgb_str,\n",
        "    digits=4,\n",
        "    zero_division=0\n",
        "))\n",
        "\n",
        "# Confusion matrix\n",
        "tun_xgb_cm = confusion_matrix(y_test, y_best_xgb_str, labels=[\"Media\", \"Alta\", \"Baja\"])\n",
        "print(\"\\nTuned XGBoost Confusion Matrix (Test Set):\\n\", tun_xgb_cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qs-zQxHbvqLW",
        "outputId": "e741b299-3956-4bea-93fb-7cecc23bcdf8"
      },
      "id": "qs-zQxHbvqLW",
      "execution_count": 266,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best XGBoost params: {'classifier__subsample': 0.8, 'classifier__n_estimators': 400, 'classifier__max_depth': 6, 'classifier__learning_rate': 0.1, 'classifier__colsample_bytree': 1.0}\n",
            "Best CV macro-F1 (XGB): 0.9224\n",
            "Tuned XGBoost Test macro-F1: 0.9575414311815337\n",
            "XGBoost Test Accuracy: 0.9825\n",
            "\n",
            "Tuned XGBoost Classification Report (Test Set):\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Alta     0.9797    0.9190    0.9484       210\n",
            "        Baja     0.9615    0.9091    0.9346       110\n",
            "       Media     0.9841    0.9952    0.9896      1680\n",
            "\n",
            "    accuracy                         0.9825      2000\n",
            "   macro avg     0.9751    0.9411    0.9575      2000\n",
            "weighted avg     0.9824    0.9825    0.9823      2000\n",
            "\n",
            "\n",
            "Tuned XGBoost Confusion Matrix (Test Set):\n",
            " [[1672    4    4]\n",
            " [  17  193    0]\n",
            " [  10    0  100]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Entendiendo el hyperparameter tunning\n",
        "- Los hiperpar√°metros son configuraciones externas que controlan c√≥mo se entrena el modelo, pero no se aprenden de los datos.\n",
        "  - Los ejemplos en XGBoost incluyen `learning_rate`, `n_estimators`, `max_depth`, `subsample` y `colsample_bytree`.\n",
        "- Los hiperpar√°metros influyen considerablemente en el rendimiento de la generalizaci√≥n. Una mala elecci√≥n (p. ej., `max_depth=1` o `learning_rate=1.0`) puede generar un underfit o un overfit.\n",
        "- Los ‚Äúmejores‚Äù valores de hiperpar√°metros dependen del conjunto de datos (tama√±o, ruido, caracter√≠sticas de las funciones).\n",
        "- `RandomizedSearchCV` muestrea aleatoriamente un n√∫mero fijo (`n_iter`) de combinaciones de hiperpar√°metros de las distribuciones o listas especificadas. En la pr√°ctica, suele encontrar soluciones casi tan buenas como una b√∫squeda en cuadr√≠cula completa, especialmente cuando solo se necesita una idea aproximada de la regi√≥n √≥ptima.\n",
        "\n",
        "Significado de cada parametro definido en el espacio\n",
        "- `\"classifier__learning_rate\": [0.01, 0.05, 0.1]`\n",
        "  - Una tasa de aprendizaje m√°s baja puede ralentizar el entrenamiento, pero a menudo produce una mejor generalizaci√≥n; una tasa m√°s alta puede converger m√°s r√°pido, pero conlleva el riesgo de overfit.\n",
        "- `\"classifier__n_estimators\": [100, 200, 400]`\n",
        "  - N√∫mero de rondas de refuerzo (√°rboles). Un mayor n√∫mero de √°rboles puede capturar mayor complejidad, pero con un mayor coste computacional.\n",
        "- `\"classifier__max_depth\": [4, 6, 8]`\n",
        "  - Profundidad m√°xima de cada √°rbol. Los √°rboles m√°s profundos pueden modelar interacciones m√°s complejas, pero tambi√©n pueden ocasionar overfit si son demasiado profundos.\n",
        "- `\"classifier__subsample\": [0.6, 0.8, 1.0]`\n",
        "  - Fracci√≥n de filas de entrenamiento utilizadas por cada √°rbol. Si la submuestra < 1,0, el algoritmo utiliza un 60 % u 80 % aleatorio de filas por √°rbol, lo que puede ayudar a reducir el overfit (como el bagging).\n",
        "- `\"classifier__colsample_bytree\": [0.6, 0.8, 1.0]`\n",
        "  - Fracci√≥n de caracter√≠sticas (columnas) consideradas por cada √°rbol. Valores m√°s bajos obligan a cada √°rbol a ver solo un subconjunto de caracter√≠sticas, lo que puede mejorar la generalizaci√≥n de forma similar al bagging de caracter√≠sticas.\n"
      ],
      "metadata": {
        "id": "YS6deRdAzreV"
      },
      "id": "YS6deRdAzreV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Retrain en el dataset completo"
      ],
      "metadata": {
        "id": "QPY_hMlTGN-_"
      },
      "id": "QPY_hMlTGN-_"
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir el pipeline final\n",
        "final_xgb_pipeline = best_xgb\n",
        "\n",
        "# Fit del pipeline en el dataset completo (10000 filas)\n",
        "final_xgb_pipeline.fit(X, y_encoded)"
      ],
      "metadata": {
        "id": "tqTSeCyzGRYx",
        "outputId": "408c7881-41c3-48d3-ec3c-9d019c890c26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "id": "tqTSeCyzGRYx",
      "execution_count": 267,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('preprocessor',\n",
              "                 ColumnTransformer(transformers=[('nums',\n",
              "                                                  Pipeline(steps=[('imputer',\n",
              "                                                                   SimpleImputer(strategy='median')),\n",
              "                                                                  ('scaler',\n",
              "                                                                   StandardScaler())]),\n",
              "                                                  ['year', 'selling_price',\n",
              "                                                   'potencia_motor_hp',\n",
              "                                                   'nivel_seguridad',\n",
              "                                                   'eficiencia_km_l']),\n",
              "                                                 ('cats',\n",
              "                                                  Pipeline(steps=[('imputer',\n",
              "                                                                   SimpleImputer(strategy='most_frequent')),\n",
              "                                                                  ('encoder',\n",
              "                                                                   OneHotEncoder(hand...\n",
              "                               feature_types=None, gamma=None, grow_policy=None,\n",
              "                               importance_type=None,\n",
              "                               interaction_constraints=None, learning_rate=0.1,\n",
              "                               max_bin=None, max_cat_threshold=None,\n",
              "                               max_cat_to_onehot=None, max_delta_step=None,\n",
              "                               max_depth=6, max_leaves=None,\n",
              "                               min_child_weight=None, missing=nan,\n",
              "                               monotone_constraints=None, multi_strategy=None,\n",
              "                               n_estimators=400, n_jobs=-1, num_class=3,\n",
              "                               num_parallel_tree=None, ...))])"
            ],
            "text/html": [
              "<style>#sk-container-id-4 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-4 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-4 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-4 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-4 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"‚ñ∏\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-4 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"‚ñæ\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-4 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-4 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-4 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-4 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-4 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-4 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
              "                 ColumnTransformer(transformers=[(&#x27;nums&#x27;,\n",
              "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
              "                                                                   SimpleImputer(strategy=&#x27;median&#x27;)),\n",
              "                                                                  (&#x27;scaler&#x27;,\n",
              "                                                                   StandardScaler())]),\n",
              "                                                  [&#x27;year&#x27;, &#x27;selling_price&#x27;,\n",
              "                                                   &#x27;potencia_motor_hp&#x27;,\n",
              "                                                   &#x27;nivel_seguridad&#x27;,\n",
              "                                                   &#x27;eficiencia_km_l&#x27;]),\n",
              "                                                 (&#x27;cats&#x27;,\n",
              "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
              "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
              "                                                                  (&#x27;encoder&#x27;,\n",
              "                                                                   OneHotEncoder(hand...\n",
              "                               feature_types=None, gamma=None, grow_policy=None,\n",
              "                               importance_type=None,\n",
              "                               interaction_constraints=None, learning_rate=0.1,\n",
              "                               max_bin=None, max_cat_threshold=None,\n",
              "                               max_cat_to_onehot=None, max_delta_step=None,\n",
              "                               max_depth=6, max_leaves=None,\n",
              "                               min_child_weight=None, missing=nan,\n",
              "                               monotone_constraints=None, multi_strategy=None,\n",
              "                               n_estimators=400, n_jobs=-1, num_class=3,\n",
              "                               num_parallel_tree=None, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
              "                 ColumnTransformer(transformers=[(&#x27;nums&#x27;,\n",
              "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
              "                                                                   SimpleImputer(strategy=&#x27;median&#x27;)),\n",
              "                                                                  (&#x27;scaler&#x27;,\n",
              "                                                                   StandardScaler())]),\n",
              "                                                  [&#x27;year&#x27;, &#x27;selling_price&#x27;,\n",
              "                                                   &#x27;potencia_motor_hp&#x27;,\n",
              "                                                   &#x27;nivel_seguridad&#x27;,\n",
              "                                                   &#x27;eficiencia_km_l&#x27;]),\n",
              "                                                 (&#x27;cats&#x27;,\n",
              "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
              "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
              "                                                                  (&#x27;encoder&#x27;,\n",
              "                                                                   OneHotEncoder(hand...\n",
              "                               feature_types=None, gamma=None, grow_policy=None,\n",
              "                               importance_type=None,\n",
              "                               interaction_constraints=None, learning_rate=0.1,\n",
              "                               max_bin=None, max_cat_threshold=None,\n",
              "                               max_cat_to_onehot=None, max_delta_step=None,\n",
              "                               max_depth=6, max_leaves=None,\n",
              "                               min_child_weight=None, missing=nan,\n",
              "                               monotone_constraints=None, multi_strategy=None,\n",
              "                               n_estimators=400, n_jobs=-1, num_class=3,\n",
              "                               num_parallel_tree=None, ...))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>preprocessor: ColumnTransformer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for preprocessor: ColumnTransformer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(transformers=[(&#x27;nums&#x27;,\n",
              "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
              "                                                  SimpleImputer(strategy=&#x27;median&#x27;)),\n",
              "                                                 (&#x27;scaler&#x27;, StandardScaler())]),\n",
              "                                 [&#x27;year&#x27;, &#x27;selling_price&#x27;, &#x27;potencia_motor_hp&#x27;,\n",
              "                                  &#x27;nivel_seguridad&#x27;, &#x27;eficiencia_km_l&#x27;]),\n",
              "                                (&#x27;cats&#x27;,\n",
              "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
              "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
              "                                                 (&#x27;encoder&#x27;,\n",
              "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
              "                                 [&#x27;transmission&#x27;, &#x27;tipo_carroceria&#x27;, &#x27;brand&#x27;])])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" ><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>nums</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;year&#x27;, &#x27;selling_price&#x27;, &#x27;potencia_motor_hp&#x27;, &#x27;nivel_seguridad&#x27;, &#x27;eficiencia_km_l&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" ><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SimpleImputer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.impute.SimpleImputer.html\">?<span>Documentation for SimpleImputer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-32\" type=\"checkbox\" ><label for=\"sk-estimator-id-32\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>StandardScaler</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-33\" type=\"checkbox\" ><label for=\"sk-estimator-id-33\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>cats</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;transmission&#x27;, &#x27;tipo_carroceria&#x27;, &#x27;brand&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-34\" type=\"checkbox\" ><label for=\"sk-estimator-id-34\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SimpleImputer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.impute.SimpleImputer.html\">?<span>Documentation for SimpleImputer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-35\" type=\"checkbox\" ><label for=\"sk-estimator-id-35\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>OneHotEncoder</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div> </div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-36\" type=\"checkbox\" ><label for=\"sk-estimator-id-36\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=1.0, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=400, n_jobs=-1, num_class=3,\n",
              "              num_parallel_tree=None, ...)</pre></div> </div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 267
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Este segmento se asegura de que el modelo de XGBoost vea cada carro del dataset completo."
      ],
      "metadata": {
        "id": "sizvgXRPG1Im"
      },
      "id": "sizvgXRPG1Im"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deployment"
      ],
      "metadata": {
        "id": "bVOp-fRECGuq"
      },
      "id": "bVOp-fRECGuq"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Extraer la importancia de cada feature para visualizaci√≥n"
      ],
      "metadata": {
        "id": "TpAbTkPIH602"
      },
      "id": "TpAbTkPIH602"
    },
    {
      "cell_type": "code",
      "source": [
        "# Extraer el XGBClassifier ya entrenado\n",
        "xgb_model = final_xgb_pipeline.named_steps[\"classifier\"]\n",
        "\n",
        "# Extraer los nombres de las features\n",
        "feature_names = final_xgb_pipeline.named_steps[\"preprocessor\"].get_feature_names_out()\n",
        "\n",
        "# Obtener las importancias de XGBoost\n",
        "importances = xgb_model.feature_importances_\n",
        "\n",
        "# Crear un DataFrame para visualizar las importancias\n",
        "importance_df = pd.DataFrame({\n",
        "    \"feature\": feature_names,\n",
        "    \"importance\": importances\n",
        "}).sort_values(by=\"importance\", ascending=False)\n",
        "\n",
        "# Mostrar las 10 features m√°s importantes\n",
        "print(\"Top 10 important features for XGBoost:\\n\")\n",
        "print(importance_df.head(10))"
      ],
      "metadata": {
        "id": "8kGezWrJIDyN",
        "outputId": "ce104553-d3fd-42d1-d8df-4e3e43f5bb11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "8kGezWrJIDyN",
      "execution_count": 268,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 important features for XGBoost:\n",
            "\n",
            "                    feature  importance\n",
            "0                nums__year    0.158627\n",
            "9   cats__tipo_carroceria_3    0.143178\n",
            "11  cats__tipo_carroceria_5    0.073652\n",
            "8   cats__tipo_carroceria_2    0.072318\n",
            "4     nums__eficiencia_km_l    0.069292\n",
            "3     nums__nivel_seguridad    0.066004\n",
            "10  cats__tipo_carroceria_4    0.065356\n",
            "2   nums__potencia_motor_hp    0.062546\n",
            "7   cats__tipo_carroceria_1    0.046031\n",
            "25         cats__brand_jeep    0.033672\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Serializar el modelo y empezar despliegue"
      ],
      "metadata": {
        "id": "N9EJtPkEJLu3"
      },
      "id": "N9EJtPkEJLu3"
    },
    {
      "cell_type": "code",
      "source": [
        "# Serializer el modelo para ser desplegado\n",
        "joblib.dump(final_xgb_pipeline, \"xgb_final_pipeline.pkl\")\n",
        "\n",
        "# Serializer el encoder para ser desplegado\n",
        "joblib.dump(le, \"label_encoder.pkl\")"
      ],
      "metadata": {
        "id": "yR20KEufHb9I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70937c66-ef39-45a1-bb37-a8391ea8c882"
      },
      "id": "yR20KEufHb9I",
      "execution_count": 269,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['label_encoder.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 269
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Ahora cualquiera puede cargar el archivo \"xgb_final_pipeline.pkl\" y correr `.predict()` en data frames nuevos que tengan las mismas columnas y dtypes"
      ],
      "metadata": {
        "id": "qXUp59baKHiO"
      },
      "id": "qXUp59baKHiO"
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}