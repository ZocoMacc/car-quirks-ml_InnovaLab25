{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Imports & Settings\n",
        "- Descargar e importar dependencias"
      ],
      "metadata": {
        "id": "ryKe98J-Bu0M"
      },
      "id": "ryKe98J-Bu0M"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Dummy baseline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, r2_score, mean_squared_error\n",
        "\n",
        "# Preprocessing (Pipelines)\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# Modeling: Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Modeling: Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "eE1_V_wWBq4H"
      },
      "id": "eE1_V_wWBq4H",
      "execution_count": 246,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Data\n",
        "- Cargar el data set\n",
        "- Primer vistazo a la distribucion"
      ],
      "metadata": {
        "id": "QctRhgn6B40Z"
      },
      "id": "QctRhgn6B40Z"
    },
    {
      "cell_type": "code",
      "source": [
        "# Get url from file hosted on GitHub\n",
        "url = \"https://raw.githubusercontent.com/ZocoMacc/car-quirks-ml_InnovaLab25/refs/heads/main/data/cars_data.csv\"\n",
        "\n",
        "# Cargar csv en un DataFrame\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Explorar la estructura del DataFrame (Sanity Check)\n",
        "df.info()\n",
        "df.shape\n",
        "# df.isna().sum().sort_values(ascending=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzqNHCXUCZTN",
        "outputId": "e6cc0c26-b2ce-447f-a061-f04690166e88"
      },
      "id": "EzqNHCXUCZTN",
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 15 columns):\n",
            " #   Column                  Non-Null Count  Dtype  \n",
            "---  ------                  --------------  -----  \n",
            " 0   name                    10000 non-null  object \n",
            " 1   year                    10000 non-null  int64  \n",
            " 2   selling_price           10000 non-null  int64  \n",
            " 3   km_driven               10000 non-null  int64  \n",
            " 4   fuel                    10000 non-null  int64  \n",
            " 5   combustible_estimado_l  10000 non-null  float64\n",
            " 6   seller_type             10000 non-null  int64  \n",
            " 7   transmission            10000 non-null  int64  \n",
            " 8   owner                   10000 non-null  int64  \n",
            " 9   tipo_carroceria         10000 non-null  int64  \n",
            " 10  potencia_motor_hp       10000 non-null  int64  \n",
            " 11  nivel_seguridad         10000 non-null  float64\n",
            " 12  calidad_auto            10000 non-null  object \n",
            " 13  score_calidad           10000 non-null  float64\n",
            " 14  eficiencia_km_l         10000 non-null  float64\n",
            "dtypes: float64(4), int64(9), object(2)\n",
            "memory usage: 1.1+ MB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 15)"
            ]
          },
          "metadata": {},
          "execution_count": 231
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ver el balance de las clases (84% Media, 10.5% Alta, 5.5% Baja)\n",
        "df[\"calidad_auto\"].value_counts(normalize=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "tfZjya5Ya2MI",
        "outputId": "930754a8-f285-4d9a-fd90-f3532232c2d9"
      },
      "id": "tfZjya5Ya2MI",
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "calidad_auto\n",
              "Media    0.8399\n",
              "Alta     0.1052\n",
              "Baja     0.0549\n",
              "Name: proportion, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>proportion</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>calidad_auto</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Media</th>\n",
              "      <td>0.8399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Alta</th>\n",
              "      <td>0.1052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Baja</th>\n",
              "      <td>0.0549</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 219
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Lo que esto nos dice\n",
        "- Un fuerte desbalanceo de clases\n",
        "  - \"Media\" es la mayoria con un 84%\n",
        "  - \"Alta\" solo cubre el 10%, y \"Baja\" solo un 5.5%\n",
        "- El accuracy de referencia (baseline) es engañosamente alto\n",
        "  - Un DummyClassifier que siempre predice \"Media\" deberia de poder predecir 83.99%.\n",
        "  - Superar este baseline no garantiza que el modelo sea mas precizo detectando \"Alta\" o \"Baja\".\n",
        "- Riesgo de abandono de las clases minoritarias\n",
        "  - El modelo tiene el riesgo de predecir \"Media\" la mayoria del tiempo debido al desbalanceo de las clases, lo que podria ignorar \"Alta\" o \"Baja\" como opciones."
      ],
      "metadata": {
        "id": "4s-HoOX8IJAh"
      },
      "id": "4s-HoOX8IJAh"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cleaning & Dropping\n",
        "- Decidir las variables que seran ignoradas por el modelo.\n",
        "- Si es necesarion, transformar valores en interpretaciones legibles por el modelo o marcarlas con una categoria."
      ],
      "metadata": {
        "id": "EujHrAybfup-"
      },
      "id": "EujHrAybfup-"
    },
    {
      "cell_type": "code",
      "source": [
        "# Duda sobre la variable \"score_calidad\": Que tanto se correlaciona con \"calidad_auto\"\n",
        "# Mapear las categorias con numeros para calcular la correlacion\n",
        "mapping = {\"Baja\": 0, \"Media\": 1, \"Alta\": 2}\n",
        "df[\"calidad_code\"] = df[\"calidad_auto\"].map(mapping)\n",
        "\n",
        "# Calcular la correlacion\n",
        "corr = df[[\"score_calidad\", \"calidad_code\"]].corr().iloc[0, 1]\n",
        "\n",
        "# Imprimir los resultados\n",
        "print(f\"Correlacion entre score_calidad y calidad_auto: {corr:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kA-E2kkjgLhv",
        "outputId": "0aa3e8f0-6f31-4955-b1bd-455dbf3598c3"
      },
      "id": "kA-E2kkjgLhv",
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlacion entre score_calidad y calidad_auto: 0.740\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Lo que esto nos dice\n",
        "- La correlacion entre \"score_calidad\" y \"calidad_auto\" no es 1.0, lo que quiere decir que \"calidad_auto\" no depende al 100% de la variable \"score_calidad\".\n",
        "- La variable \"score_calidad\" va a ser considerada."
      ],
      "metadata": {
        "id": "ZTNtSbS-hsXo"
      },
      "id": "ZTNtSbS-hsXo"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Extraer marca del nombre\n",
        "- Usar el nombre y cortarlo de una manera en la que podamos extrar la marca del auto para poder usarlo como variable y ser considerada."
      ],
      "metadata": {
        "id": "W7UU6SNHlHoE"
      },
      "id": "W7UU6SNHlHoE"
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Rifense este rollo porfi\n",
        "- Extraer el nombre de la marca de cada carro (crar una columna para \"brand\")\n",
        "- Investigar si es viable extraer tambien el submodelo del carro (Limited, Sport, AC, ZX, etc)\n",
        "  - Maybe no nos conviene por que son un chingo pero maybe si si no son tantas quien sabe\n",
        "  - Si si es viable crear una columna para \"submodel\"\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "-0SgRIRHmF5z"
      },
      "id": "-0SgRIRHmF5z",
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Convertir columnas de enteros en categorias\n",
        "- Columnas como \"fuel\", \"seller_type\", \"transmission\", \"owner\", \"tipo_carroceria\" tienen asignado un valor entero pero en realidad representan categorias sin orden.\n",
        "- Convertir estas variables a Pandas' category dtype para mas claridad y eficiencia en la manipulacion de estas variables, tambien es mas seguro hacerlo de esta forma, asi evitamos que estas columnas se interpreten como numeric imputers o scalers."
      ],
      "metadata": {
        "id": "43A-JGJKnxf2"
      },
      "id": "43A-JGJKnxf2"
    },
    {
      "cell_type": "code",
      "source": [
        "cat_int_cols = [\n",
        "    \"fuel\",\n",
        "    \"seller_type\",\n",
        "    \"transmission\",\n",
        "    \"owner\",\n",
        "    \"tipo_carroceria\"\n",
        "    #\"brand\"             # caegoria extraida del nombre\n",
        "]\n",
        "\n",
        "for col in cat_int_cols:\n",
        "    df[col] = df[col].astype(\"category\")"
      ],
      "metadata": {
        "id": "CZlrE_CHn9ZP"
      },
      "id": "CZlrE_CHn9ZP",
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Droppear columnas innecesarias"
      ],
      "metadata": {
        "id": "xJL2hxc2NKNk"
      },
      "id": "xJL2hxc2NKNk"
    },
    {
      "cell_type": "code",
      "source": [
        "# Al final se droppea el nombre (ya teniendo la brand y el submodel no lo necesitamos)\n",
        "df = df.drop(columns=[\"name\"])\n",
        "\n",
        "# Ver correlaciones para identificar leaks\n",
        "correlations = df.drop(columns=[\"calidad_auto\"]).corrwith(df[\"calidad_code\"])\n",
        "print(\"Correlaciones\")\n",
        "print(correlations.sort_values(ascending=False))\n",
        "\n",
        "# Droppera la columna helper que definimos previemente\n",
        "df = df.drop(columns=[\"calidad_code\"])\n",
        "\n",
        "print(\"\\nColumnas que permanecen en el DataFrame:\")\n",
        "print(df.dtypes)  # Checar las columnas que permanecen\n",
        "\n",
        "# Define X and y for training\n",
        "features_to_drop = [\"calidad_auto\"]\n",
        "X = df.drop(columns=features_to_drop)\n",
        "y = df[\"calidad_auto\"]    # Estableciendo el target\n",
        "\n",
        "# Inspeccionar las variables que permanecen\n",
        "# print(\"Columnas a considerar:\\n\", X.columns.tolist())\n",
        "print(\"\\nFeature dtypes (para X):\")\n",
        "print(X.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "te-8G4rdNOT0",
        "outputId": "cc2761d3-0a36-4c2b-d4ba-f64997fa6d62"
      },
      "id": "te-8G4rdNOT0",
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlaciones\n",
            "calidad_code              1.000000\n",
            "score_calidad             0.740022\n",
            "eficiencia_km_l           0.526133\n",
            "nivel_seguridad           0.497154\n",
            "year                      0.495617\n",
            "potencia_motor_hp         0.294303\n",
            "transmission              0.197374\n",
            "selling_price             0.103824\n",
            "fuel                      0.031103\n",
            "seller_type               0.028950\n",
            "km_driven                -0.024826\n",
            "tipo_carroceria          -0.033271\n",
            "owner                    -0.045147\n",
            "combustible_estimado_l   -0.107143\n",
            "dtype: float64\n",
            "\n",
            "Columnas que permanecen en el DataFrame:\n",
            "year                         int64\n",
            "selling_price                int64\n",
            "km_driven                    int64\n",
            "fuel                      category\n",
            "combustible_estimado_l     float64\n",
            "seller_type               category\n",
            "transmission              category\n",
            "owner                     category\n",
            "tipo_carroceria           category\n",
            "potencia_motor_hp            int64\n",
            "nivel_seguridad            float64\n",
            "calidad_auto                object\n",
            "score_calidad              float64\n",
            "eficiencia_km_l            float64\n",
            "dtype: object\n",
            "\n",
            "Feature dtypes (para X):\n",
            "year                         int64\n",
            "selling_price                int64\n",
            "km_driven                    int64\n",
            "fuel                      category\n",
            "combustible_estimado_l     float64\n",
            "seller_type               category\n",
            "transmission              category\n",
            "owner                     category\n",
            "tipo_carroceria           category\n",
            "potencia_motor_hp            int64\n",
            "nivel_seguridad            float64\n",
            "score_calidad              float64\n",
            "eficiencia_km_l            float64\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DummyClassifier & Baseline\n",
        "- El primer paso es establecer una baseline y asegurarse de que la informacion esta limpia\n",
        "- El objetivo es confirmar ques este DummyClassifier de como resultado una precision de 83.99%\n",
        "- Se usara la estrategia de \"most_frequent\", simplemente el valor que mas se repite sera elegido para la prediccion.\n",
        "- Este modelo representa el piso (baseline) de qualquier modelo futuro.\n",
        "- El split para entrenamiento es un 80/20 asegurandose de que cada clase aparece con las misma proporciones.\n",
        "\n"
      ],
      "metadata": {
        "id": "Ng1LdD5yB6_t"
      },
      "id": "Ng1LdD5yB6_t"
    },
    {
      "cell_type": "code",
      "source": [
        "# Establecer split (Train/Test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,    # 80/20 split\n",
        "    stratify=y,       # preserva los ratios 84/10.5/5.5 para train y test\n",
        "    random_state=99\n",
        ")\n",
        "\n",
        "# Test\n",
        "# print(\"Train class proportions:\\n\", y_train.value_counts(normalize=True))\n",
        "# print(\"\\nTest class proportions:\\n\", y_test.value_counts(normalize=True))\n",
        "\n",
        "# Iniciar DummyClassifier\n",
        "dummy = DummyClassifier(\n",
        "    strategy=\"most_frequent\", # Siempre predice la clase mas frecuente (\"Media\")\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "dummy.fit(X_train, y_train)     # \"Entrena\" basado en la clase mas frecuente\n",
        "\n",
        "# Obtener predicciones\n",
        "y_pred = dummy.predict(X_test)  # Aplica la regla a cada fila de X_test\n",
        "\n",
        "# Evaluar accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)   # Fraccion de predicciones correctas\n",
        "print(f\"DummyClassifier Accuracy: {accuracy}\")\n",
        "\n",
        "# Visualizar resulatdos de predicciones\n",
        "print(\"Classification report:\\n\")\n",
        "print(classification_report(\n",
        "    y_test,\n",
        "    y_pred,\n",
        "    digits=4,         # Numero de decimales\n",
        "    zero_division=0   # Ignorar zero-division errors (debido a strings)\n",
        "))\n",
        "\n",
        "# Generar confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred, labels=[\"Media\",\"Alta\",\"Baja\"])\n",
        "print(\"Confusion Matrix:\\n\", cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WC8kJNPZM2Xt",
        "outputId": "2c929157-df79-4f94-b3af-668ad33e434f"
      },
      "id": "WC8kJNPZM2Xt",
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DummyClassifier Accuracy: 0.84\n",
            "Classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Alta     0.0000    0.0000    0.0000       210\n",
            "        Baja     0.0000    0.0000    0.0000       110\n",
            "       Media     0.8400    1.0000    0.9130      1680\n",
            "\n",
            "    accuracy                         0.8400      2000\n",
            "   macro avg     0.2800    0.3333    0.3043      2000\n",
            "weighted avg     0.7056    0.8400    0.7670      2000\n",
            "\n",
            "Confusion Matrix:\n",
            " [[1680    0    0]\n",
            " [ 210    0    0]\n",
            " [ 110    0    0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Lo que esto nos dice\n",
        "- Tenemos un baseline de ~84% accuracy, este es el objetivo a vencer en los proximos modelos."
      ],
      "metadata": {
        "id": "wgRyZpmLYjPP"
      },
      "id": "wgRyZpmLYjPP"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data preprocessing\n",
        "- Preparar el data set para ser procesado\n",
        "- Dividir entre variables numericas y categoricas\n",
        "- Implementar un pipeline para cada tipo de variable\n",
        "- Usar ColumnTransformer para aplicar los pipelines al DataFrame"
      ],
      "metadata": {
        "id": "PSOmYyV3CAqt"
      },
      "id": "PSOmYyV3CAqt"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Identificar columnas en base al dtype"
      ],
      "metadata": {
        "id": "zx671--0xzfX"
      },
      "id": "zx671--0xzfX"
    },
    {
      "cell_type": "code",
      "source": [
        "# Datos numericos\n",
        "num_cols = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
        "print(\"Numeric features:\", num_cols)\n",
        "\n",
        "# Datos categoricos\n",
        "cat_cols = X.select_dtypes(include=[\"category\"]).columns.tolist()\n",
        "print(\"\\nCategorical features:\", cat_cols)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kU_JcFDaxLl4",
        "outputId": "6214a9e5-905f-4ac6-a0cb-9e7a5bfd0da2"
      },
      "id": "kU_JcFDaxLl4",
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numeric features: ['year', 'selling_price', 'km_driven', 'combustible_estimado_l', 'potencia_motor_hp', 'nivel_seguridad', 'score_calidad', 'eficiencia_km_l']\n",
            "\n",
            "Categorical features: ['fuel', 'seller_type', 'transmission', 'owner', 'tipo_carroceria']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Construir el pipeline numerico"
      ],
      "metadata": {
        "id": "4h0v9hENyWIX"
      },
      "id": "4h0v9hENyWIX"
    },
    {
      "cell_type": "code",
      "source": [
        "num_pipe = Pipeline([\n",
        "    # Definiendo tecnicas de defensive programming\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\")), # Imputacion de media\n",
        "    (\"scaler\", StandardScaler())                   # Standard scaling\n",
        "])"
      ],
      "metadata": {
        "id": "vepTzJLPyYXG"
      },
      "id": "vepTzJLPyYXG",
      "execution_count": 237,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- El objetivo de la funcion `SimpleImputer()` es remplazar valores faltantes por el valor definido por su argumento (e.g. median).\n",
        "- El objetivo de la funcion `StandardScaler()` es que despues de una imputacion, el valor numerico es escalado para tener una media = 0 y standard deviation = 1. De esta forma se evitan posibles errores generados por tener diferentes escalas de numeros en las diferentes columnas."
      ],
      "metadata": {
        "id": "cyk6t5x1y9ad"
      },
      "id": "cyk6t5x1y9ad"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Construir el pipeline categorico"
      ],
      "metadata": {
        "id": "A-TcmKaA0xQd"
      },
      "id": "A-TcmKaA0xQd"
    },
    {
      "cell_type": "code",
      "source": [
        "cat_pipe = Pipeline([\n",
        "    # Definiendo tecnicas de defensive programming\n",
        "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),  # Imputacion de moda\n",
        "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))    # One-hot encoding\n",
        "])"
      ],
      "metadata": {
        "id": "5WypSVy705LP"
      },
      "id": "5WypSVy705LP",
      "execution_count": 238,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `SimpleImputer()` remplaza cualquier valor faltante por el valor mas frecuente (la moda). Esto preserva la distribucion del data set.\n",
        "- El objetivo del OneHotEncoder es convertir cada columna categorica en las columnas binarias necesarias para representar cada valor categorico unico.\n",
        "  - `handle_unkwnown=\"ignore\"` es util para que en caso de que aparezca una nueva categoria \"vacia\", que esta sea representada por una columna entera de puros ceros."
      ],
      "metadata": {
        "id": "3EmHAM6wBJWM"
      },
      "id": "3EmHAM6wBJWM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Implementacion de ColumnTransformer para aplicar los pipelines"
      ],
      "metadata": {
        "id": "KlPpE_hsE6D_"
      },
      "id": "KlPpE_hsE6D_"
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        # Aplicar num_pipe a las columnas numericas\n",
        "        (\"nums\", num_pipe, num_cols),\n",
        "        # Aplicar cat_pipe a columnas categoricas\n",
        "        (\"cats\", cat_pipe, cat_cols)\n",
        "    ],\n",
        "    remainder=\"drop\" # Tirar cualquier columna no listada\n",
        ")"
      ],
      "metadata": {
        "id": "a1xq23TBFJSe"
      },
      "id": "a1xq23TBFJSe",
      "execution_count": 239,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `transformers` es un array de tuples `(name, pipeline, columns)` que ira siendo populado mientras `.fit()` corre\n",
        "  1. `(\"nums\", num_pipe, num_cols)` toma todas las columnas en `num_cols` y aplica el pipeline `num_pipe` y entraga como output el array numerico transformado.\n",
        "  2. `(\"cats\", cat_pipe, cat_cols)` toma todas las columnas en `cat_cols` y aplica el pipeline `cat_pipe` y entraga como output el array categorico transformado."
      ],
      "metadata": {
        "id": "kl43BKMVJVR3"
      },
      "id": "kl43BKMVJVR3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Inspeccionar el output transformado"
      ],
      "metadata": {
        "id": "q3596Gl4KnfD"
      },
      "id": "q3596Gl4KnfD"
    },
    {
      "cell_type": "code",
      "source": [
        "# Testear el preprocessor\n",
        "preprocessor.fit(X_train)\n",
        "\n",
        "# Ver la forma del array final\n",
        "X_train_transformed = preprocessor.transform(X_train)\n",
        "print(\"Transformed shape:\", X_train_transformed.shape)\n",
        "#print(len(num_cols))\n",
        "\n",
        "# Imprimir las columnas finales\n",
        "feature_names = preprocessor.get_feature_names_out()\n",
        "print(\"All output features:\\n\", feature_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7F5TjTMKufV",
        "outputId": "8965dece-f0be-4cac-aa1c-d1b8186d9670"
      },
      "id": "z7F5TjTMKufV",
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformed shape: (8000, 28)\n",
            "All output features:\n",
            " ['nums__year' 'nums__selling_price' 'nums__km_driven'\n",
            " 'nums__combustible_estimado_l' 'nums__potencia_motor_hp'\n",
            " 'nums__nivel_seguridad' 'nums__score_calidad' 'nums__eficiencia_km_l'\n",
            " 'cats__fuel_0' 'cats__fuel_1' 'cats__fuel_2' 'cats__fuel_3'\n",
            " 'cats__fuel_4' 'cats__seller_type_0' 'cats__seller_type_1'\n",
            " 'cats__seller_type_2' 'cats__transmission_0' 'cats__transmission_1'\n",
            " 'cats__owner_0' 'cats__owner_1' 'cats__owner_2' 'cats__owner_3'\n",
            " 'cats__owner_4' 'cats__tipo_carroceria_1' 'cats__tipo_carroceria_2'\n",
            " 'cats__tipo_carroceria_3' 'cats__tipo_carroceria_4'\n",
            " 'cats__tipo_carroceria_5']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Lo que esto nos dice\n",
        "- En total hay 28 columnas ya con los pipelines aplicados (8 numericas y 20 categoricas) - temporal (falta agregar \"brand\" y talvez \"submodel\")\n",
        "- Los prefijos `nums_` y `cats_` nos dicen de cual pipeline proviene cada columna\n",
        "- Estos nombres nos serviran despues para implementacion de funciones o debugging"
      ],
      "metadata": {
        "id": "SZumUwvGMuMR"
      },
      "id": "SZumUwvGMuMR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression\n",
        "- La regresión logística es una técnica de análisis de datos que utiliza las matemáticas para encontrar las relaciones entre dos factores de datos. Luego, utiliza esta relación para predecir el valor de uno de esos factores basándose en el otro. Normalmente, la predicción tiene un número finito de resultados, como un sí o un no."
      ],
      "metadata": {
        "id": "H2t9M4f-R5j2"
      },
      "id": "H2t9M4f-R5j2"
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un objecto de LogisticRegression\n",
        "logreg = LogisticRegression(\n",
        "    multi_class=\"multinomial\",   # Clasificacion multiclase\n",
        "    solver=\"saga\",               # Algoritmo de optimizacion (soporta L1/L2)\n",
        "    class_weight=\"balanced\",     # Ajuste de pesos para clases desbalanceadas\n",
        "    max_iter=1000,               # Numero maximo de iteraciones\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Construir un unico pipeline\n",
        "lr_pipeline = Pipeline([\n",
        "    (\"preprocessor\", preprocessor),\n",
        "    (\"classifier\", logreg)\n",
        "])\n",
        "\n",
        "# usar 5-fold cross-validation para evaluar el modelo de regresion logistica\n",
        "cv_macro_f1 = cross_val_score(\n",
        "    lr_pipeline,    # Pipeline completeo\n",
        "    X,              # Todas las features\n",
        "    y,              # Todas las labels\n",
        "    cv=5,           # 5 folds\n",
        "    scoring=\"f1_macro\", # macro-averaged F1\n",
        "    n_jobs=-1       # Usar todos los nucleos del CPU\n",
        ")\n",
        "\n",
        "# Imprimir los fold scores y la media\n",
        "print(\"Logistic Regression 5-fold CV macro-F1 scores:\", cv_macro_f1.round(4))\n",
        "print(\"Mean macro-F1:\", cv_macro_f1.mean().round(4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSvhbZ08R-Ig",
        "outputId": "176cc42b-4d7d-4784-c1b2-cf646dc921da"
      },
      "id": "wSvhbZ08R-Ig",
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression 5-fold CV macro-F1 scores: [0.9628 0.9345 0.9242 0.9081 0.9075]\n",
            "Mean macro-F1: 0.9274\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Entendiendo de la media Macro-F1\n",
        "- La evaluacion multiclase Macro-F1 toma el promedio no ponderado de los tres puntajes F1 por clase (\"Alta\", \"Media\", \"Baja\"). Este proceso toma cada clase de forma equivalente aunque la distribucion sea diferente (10.5%, 84%, 5.5%). Usando macro-F1 nos aseguramos de que el modelo no esta eligiendo \"Media\" en todas las predicciones y realmente esta prediciendo entre las tres clases.\n",
        "- El metodo de evaluacion 5-fold cross-validation es una manera de estimar que tan bien el pipeline (preprocessor + modelo) se generaliza a datasets no vistos\n",
        "  - Se divide el dataset completo entre 5 subsets (folds), en este caso cada fold tiene aproximadamente 2000 carros.\n",
        "  - Al final obtenemos 5 scores, una por cada subset, esto en toeria refleja que tan bien se comportaria el pipeline si fuera un \"nuevo\" dataset. El promedio de esas 5 scores es lo que llamamos mean macro-F1."
      ],
      "metadata": {
        "id": "53QQETV7uJtP"
      },
      "id": "53QQETV7uJtP"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Lo que los resulatados del Macro-F1 nos dicen\n",
        "- Los 5 scores estan arribe de 0.90, lo que quiere decir que el pipeline esta consistentemente obteniendo un score alto en \"nueva\" informacion.\n",
        "- La media macro-F1 de 0.9274 es el mejor resumen numérico del \"rendimiento esperado\" si se entrenó con el 80 % del conjunto de datos y se probó con el 20 % restante. Esto sugiere que, en promedio, el modelo clasifica correctamente casi todos los ejemplos de \"Media\" y también funciona bien con \"Alta\" y \"Baja\"."
      ],
      "metadata": {
        "id": "0iNV3UqJyHRt"
      },
      "id": "0iNV3UqJyHRt"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Logistic Regression Training & Testing\n"
      ],
      "metadata": {
        "id": "TydGfRBNdysi"
      },
      "id": "TydGfRBNdysi"
    },
    {
      "cell_type": "code",
      "source": [
        "# Test 1\n",
        "# Establecer split (Train/Test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,    # 80/20 split\n",
        "    stratify=y,       # preserva los ratios 84/10.5/5.5 para train y test\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Asegurarse de las columnas presentes en X_train\n",
        "print(\"Columns in X_train:\", X_train.columns.tolist())\n",
        "\n",
        "# Fit X_train, y_train (80%) y evaluar en X_test, y_test (20%)\n",
        "lr_pipeline.fit(X_train, y_train)\n",
        "y_test_pred = lr_pipeline.predict(X_test)\n",
        "\n",
        "# Evaluar el test\n",
        "test_acc = accuracy_score(y_test, y_test_pred)\n",
        "print(f\"Logistic Regression Test Accuracy: {test_acc:.4f}\")\n",
        "print(\"\\nLogistic Regression Test Classification Report:\\n\")\n",
        "print(classification_report(\n",
        "    y_test,\n",
        "    y_test_pred,\n",
        "    digits=4,         # Numero de decimales\n",
        "    zero_division=0   # Ignorar zero-division errors (debido a strings)\n",
        "))\n",
        "\n",
        "# Generar confusion matrix\n",
        "cm = confusion_matrix(y_test, y_test_pred, labels=[\"Media\",\"Alta\",\"Baja\"])\n",
        "print(\"Confusion Matrix:\\n\", cm)"
      ],
      "metadata": {
        "id": "1-xrcNyzzVIZ",
        "outputId": "f94a7b82-3af8-49b4-864d-7fe5ecd06be9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "1-xrcNyzzVIZ",
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns in X_train: ['year', 'selling_price', 'km_driven', 'fuel', 'combustible_estimado_l', 'seller_type', 'transmission', 'owner', 'tipo_carroceria', 'potencia_motor_hp', 'nivel_seguridad', 'score_calidad', 'eficiencia_km_l']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Test Accuracy: 0.9700\n",
            "\n",
            "Logistic Regression Test Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Alta     0.8936    1.0000    0.9438       210\n",
            "        Baja     0.7586    1.0000    0.8627       110\n",
            "       Media     1.0000    0.9643    0.9818      1680\n",
            "\n",
            "    accuracy                         0.9700      2000\n",
            "   macro avg     0.8841    0.9881    0.9295      2000\n",
            "weighted avg     0.9756    0.9700    0.9713      2000\n",
            "\n",
            "Confusion Matrix:\n",
            " [[1620   25   35]\n",
            " [   0  210    0]\n",
            " [   0    0  110]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test 2\n",
        "# 3.3.1 New random split\n",
        "X2_train, X2_test, y2_train, y2_test = train_test_split(\n",
        "    X, y, test_size=0.20, stratify=y, random_state=99\n",
        ")\n",
        "\n",
        "# 3.3.2 Re‐fit your original pipeline (with score_calidad)\n",
        "lr_pipeline.fit(X2_train, y2_train)\n",
        "y2_pred = lr_pipeline.predict(X2_test)\n",
        "\n",
        "acc2 = accuracy_score(y2_test, y2_pred)\n",
        "print(f\"New split (seed=99) Test Accuracy: {acc2:.4f}\")\n",
        "print(\"\\nNew split Classification Report:\\n\")\n",
        "print(classification_report(y2_test, y2_pred, digits=4, zero_division=0))\n",
        "\n",
        "# Generar confusion matrix\n",
        "cm = confusion_matrix(y2_test, y2_pred, labels=[\"Media\",\"Alta\",\"Baja\"])\n",
        "print(\"Confusion Matrix:\\n\", cm)"
      ],
      "metadata": {
        "id": "TNQUsmC5HPc8",
        "outputId": "daa1ed32-1896-4fd8-ebed-36faf0eab34e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "TNQUsmC5HPc8",
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New split (seed=99) Test Accuracy: 0.9730\n",
            "\n",
            "New split Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Alta     0.8898    1.0000    0.9417       210\n",
            "        Baja     0.7971    1.0000    0.8871       110\n",
            "       Media     1.0000    0.9679    0.9837      1680\n",
            "\n",
            "    accuracy                         0.9730      2000\n",
            "   macro avg     0.8956    0.9893    0.9375      2000\n",
            "weighted avg     0.9773    0.9730    0.9739      2000\n",
            "\n",
            "Confusion Matrix:\n",
            " [[1626   26   28]\n",
            " [   0  210    0]\n",
            " [   0    0  110]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Testing Logistic Regression"
      ],
      "metadata": {
        "id": "oQOPPp6yTVgh"
      },
      "id": "oQOPPp6yTVgh"
    },
    {
      "cell_type": "code",
      "source": [
        "# Input entry test\n",
        "lr_pipeline.fit(X_train, y_train)\n",
        "\n",
        "X.columns.tolist()\n",
        "\n",
        "new_car_data = {\n",
        "    \"year\": [2018],                   # int\n",
        "    \"selling_price\": [350000],        # int or float\n",
        "    \"km_driven\": [25000],             # int\n",
        "    \"fuel\": [1],                      # must match the same category codes you used\n",
        "    \"combustible_estimado_l\": [1800.0],  # float\n",
        "    \"seller_type\": [0],               # category code\n",
        "    \"transmission\": [1],              # category code\n",
        "    \"owner\": [0],                     # category code\n",
        "    \"tipo_carroceria\": [2],           # category code\n",
        "    \"potencia_motor_hp\": [120],       # int\n",
        "    \"nivel_seguridad\": [4.5],         # float\n",
        "    \"score_calidad\": [5.5],           # float\n",
        "    \"eficiencia_km_l\": [18.0]         # float\n",
        "    # \"brand\": [\"Toyota\"]             # string; will be cast to category below\n",
        "}\n",
        "\n",
        "new_car_df = pd.DataFrame(new_car_data)\n",
        "\n",
        "cat_cols = [\"fuel\", \"seller_type\", \"transmission\", \"owner\", \"tipo_carroceria\"]\n",
        "for col in cat_cols:\n",
        "    new_car_df[col] = new_car_df[col].astype(\"category\")\n",
        "\n",
        "# new_car_df[\"brand\"] = new_car_df[\"brand\"].astype(\"category\")\n",
        "\n",
        "print(new_car_df.dtypes)\n",
        "\n",
        "predicted_label = lr_pipeline.predict(new_car_df)\n",
        "print(\"\\nPredicted calidad_auto:\", predicted_label[0])\n",
        "\n",
        "predicted_proba = lr_pipeline.predict_proba(new_car_df)\n",
        "print(\"Predicted probabilities [Alta, Media, Baja]:\", predicted_proba[0])"
      ],
      "metadata": {
        "id": "Erwroz9ed6i4",
        "outputId": "28c9522f-6c2e-45a5-f6c4-c5c038c1cb99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Erwroz9ed6i4",
      "execution_count": 251,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "year                         int64\n",
            "selling_price                int64\n",
            "km_driven                    int64\n",
            "fuel                      category\n",
            "combustible_estimado_l     float64\n",
            "seller_type               category\n",
            "transmission              category\n",
            "owner                     category\n",
            "tipo_carroceria           category\n",
            "potencia_motor_hp            int64\n",
            "nivel_seguridad            float64\n",
            "score_calidad              float64\n",
            "eficiencia_km_l            float64\n",
            "dtype: object\n",
            "\n",
            "Predicted calidad_auto: Media\n",
            "Predicted probabilities [Alta, Media, Baja]: [1.65544779e-04 1.17572775e-15 9.99834455e-01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest\n",
        "- Random Forest es un algoritmo de aprendizaje supervisado en machine learning que utiliza múltiples árboles de decisión para clasificar o predecir datos. Es un método de conjunto (ensemble method) que mejora la precisión de las predicciones combinando los resultados de varios modelos débiles (árboles de decisión)."
      ],
      "metadata": {
        "id": "GH-jnMM-gSKE"
      },
      "id": "GH-jnMM-gSKE"
    },
    {
      "cell_type": "code",
      "source": [
        "# Construir e inicializar un RandomForestClassifer\n",
        "rf_clf = RandomForestClassifier(\n",
        "    n_estimators=300,     # Numero de arboles en el bosque\n",
        "    max_depth=None,       # Profundidad maxima de los arboles\n",
        "    class_weight=\"balanced\",  # Ajuste de pesos para clases desbalanceadas\n",
        "    min_samples_split=2,  # Minimo numero de muestras requeridas para dividir\n",
        "    random_state=42,      # Seed\n",
        "    n_jobs=-1             # Usar todos los nucleos del CPU\n",
        ")\n",
        "\n",
        "# Crear un Pipeline unico que aplica el preprocessor previamente definido\n",
        "rf_pipeline = Pipeline([\n",
        "    (\"preprocessor\", preprocessor),   # Aplicar el preprocessor (ColumnTransformer)\n",
        "    (\"classifier\", rf_clf)\n",
        "])"
      ],
      "metadata": {
        "id": "58rnhuodgpHZ"
      },
      "id": "58rnhuodgpHZ",
      "execution_count": 253,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ],
      "metadata": {
        "id": "bVOp-fRECGuq"
      },
      "id": "bVOp-fRECGuq"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yR20KEufHb9I"
      },
      "id": "yR20KEufHb9I",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}